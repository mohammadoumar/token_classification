{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d8d957",
   "metadata": {},
   "source": [
    "# Run BERT and DistilBERT with and without finetuning the internal weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d673e4",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b5b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48289/3388413685.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84540c",
   "metadata": {},
   "source": [
    "## Launch Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ce865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_d = {\n",
    "    'model' : ['bert', 'distilbert'],\n",
    "    'finetune_mode' : [0, 1]\n",
    "}\n",
    "\n",
    "keys, values = zip(*experiments_d.items())\n",
    "\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd60550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'bert', 'finetune_mode': 0},\n",
       " {'model': 'bert', 'finetune_mode': 1},\n",
       " {'model': 'distilbert', 'finetune_mode': 0},\n",
       " {'model': 'distilbert', 'finetune_mode': 1}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dec4426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4d0d585ee549c78e17a10515035d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --model bert --finetune_mode 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (../conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n",
      "100%|██████████| 15/15 [00:01<00:00,  9.87ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.77ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.02ba/s]\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2195\n",
      "  5%|▍         | 100/2195 [00:11<03:59,  8.73it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.01it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 21.02it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.25it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.21it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.54it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 17.06it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.70it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.46it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.26it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.25it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.13it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.04it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.96it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.02it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.98it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.59it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.74it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.54it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.21it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.76it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.22it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.46it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.61it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.74it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.84it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.16it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.37it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.51it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.39it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.78it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.39it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.96it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.85it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.66it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.64it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.59it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.59it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.51it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.41it/s]\u001b[A\n",
      "                                                  [A\n",
      "  5%|▍         | 100/2195 [00:18<03:59,  8.73it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.12it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/special_tokens_map.json\n",
      "  9%|▉         | 200/2195 [00:30<03:43,  8.95it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.68it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.60it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.94it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.85it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.27it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.87it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.52it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.35it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.20it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.07it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.00it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.94it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.90it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.69it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.57it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.20it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.35it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.28it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.97it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.48it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.74it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.02it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.26it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.31it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.52it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.97it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.38it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.52it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.44it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.84it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.43it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.12it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.90it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.79it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.58it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.56it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.46it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.43it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.45it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.52it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.45it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.34it/s]\u001b[A\n",
      "                                                  [A\n",
      "  9%|▉         | 200/2195 [00:37<03:43,  8.95it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.12it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/special_tokens_map.json\n",
      " 14%|█▎        | 300/2195 [00:49<03:26,  9.18it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.22it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.99it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.16it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.08it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.44it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.95it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.64it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.44it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.30it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.15it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.01it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.01it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.89it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.94it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.82it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.53it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.74it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.69it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.44it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.94it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.24it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.57it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.65it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.75it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.84it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.14it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.34it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.49it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.46it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.86it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.44it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.16it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.98it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.86it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.77it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.59it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.57it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.43it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.30it/s]\u001b[A\n",
      "                                                  [A\n",
      " 14%|█▎        | 300/2195 [00:56<03:26,  9.18it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.02it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100] due to args.save_total_limit\n",
      " 18%|█▊        | 400/2195 [01:08<03:30,  8.54it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.46it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.49it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.82it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.76it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.11it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.66it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.38it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.11it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.00it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.89it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.86it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.80it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.80it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.71it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.72it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.37it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.45it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.34it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.07it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.57it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.98it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.32it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.56it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.74it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.83it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.08it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.38it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.57it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.54it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.88it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.46it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.22it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.03it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.84it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.64it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.55it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.57it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.61it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.49it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.32it/s]\u001b[A\n",
      "                                                  [A\n",
      " 18%|█▊        | 400/2195 [01:15<03:30,  8.54it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.95it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200] due to args.save_total_limit\n",
      " 23%|██▎       | 500/2195 [01:27<03:20,  8.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.49it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.39it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.83it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.81it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.24it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.74it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.44it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.17it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.04it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.93it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.88it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.78it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.74it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.79it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.50it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.57it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.54it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.25it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.86it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.24it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.55it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.77it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.93it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.03it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.31it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.61it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.75it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.58it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.94it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.53it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.25it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.02it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.85it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.78it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.73it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.56it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.54it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.55it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.53it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.43it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.30it/s]\u001b[A\n",
      "                                                  [A\n",
      " 23%|██▎       | 500/2195 [01:34<03:20,  8.46it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.03it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300] due to args.save_total_limit\n",
      " 27%|██▋       | 600/2195 [01:46<03:06,  8.54it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.61it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.58it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.83it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.80it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.15it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.75it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.44it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.28it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.15it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.99it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.89it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.83it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.79it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.75it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.74it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.38it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.44it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.16it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.88it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.49it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.93it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.28it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.35it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.47it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.67it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.95it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.31it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.51it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.43it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.75it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.30it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.04it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.93it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.81it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.73it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.73it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.57it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.37it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.25it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.07it/s]\u001b[A\n",
      "                                                  [A\n",
      " 27%|██▋       | 600/2195 [01:53<03:06,  8.54it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.66it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400] due to args.save_total_limit\n",
      " 32%|███▏      | 700/2195 [02:05<02:55,  8.50it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.01it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.70it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.83it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.88it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.17it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.68it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.40it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.23it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.02it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.61it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:05, 15.54it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.46it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.49it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.54it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.34it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 15.99it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.22it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.13it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.89it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.46it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.86it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.19it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.41it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.56it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.65it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.02it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.37it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.54it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.49it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.82it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.42it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.15it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.00it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.86it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.52it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.49it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.50it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.52it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.49it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.32it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.15it/s]\u001b[A\n",
      "                                                  [A\n",
      " 32%|███▏      | 700/2195 [02:12<02:55,  8.50it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.85it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500] due to args.save_total_limit\n",
      " 36%|███▋      | 800/2195 [02:26<02:40,  8.69it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.40it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.35it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.68it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.68it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.06it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.59it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.26it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.01it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 15.91it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.10it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:05, 15.26it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:05, 15.36it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.46it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.53it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.58it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.14it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.34it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.30it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.98it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.57it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.93it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.18it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.41it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.57it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.82it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.12it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.44it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.63it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.59it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.96it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.54it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.25it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.01it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.85it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.72it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.66it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.66it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.48it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.35it/s]\u001b[A\n",
      "                                                  [A\n",
      " 36%|███▋      | 800/2195 [02:32<02:40,  8.69it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.03it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600] due to args.save_total_limit\n",
      " 41%|████      | 900/2195 [02:45<02:21,  9.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.66it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.57it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.82it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.74it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.15it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.73it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.39it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.22it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.05it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.00it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.95it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.85it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.84it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.84it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.37it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.50it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.31it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.98it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.60it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.04it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.35it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.51it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.46it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.50it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.83it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.25it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.46it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.47it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.76it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.29it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 10.99it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.87it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.77it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.69it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.58it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.56it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.56it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.59it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.57it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.43it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.31it/s]\u001b[A\n",
      "                                                  [A\n",
      " 41%|████      | 900/2195 [02:52<02:21,  9.13it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.03it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700] due to args.save_total_limit\n",
      " 46%|████▌     | 1000/2195 [03:04<02:17,  8.70it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.72it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.67it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.91it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.81it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.21it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.80it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.55it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.27it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.11it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.02it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.83it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.69it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.67it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.59it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.56it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.16it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.36it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.29it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.01it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.52it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.77it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.16it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.43it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.56it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.55it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.86it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.18it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.47it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.38it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.69it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.28it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 10.96it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.80it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.68it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.54it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.43it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.40it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:06<00:01, 10.42it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.40it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.44it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.36it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.24it/s]\u001b[A\n",
      "                                                   A\n",
      " 46%|████▌     | 1000/2195 [03:11<02:17,  8.70it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.92it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800] due to args.save_total_limit\n",
      " 50%|█████     | 1100/2195 [03:24<02:09,  8.46it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.43it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.35it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.74it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.71it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 16.97it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.55it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.23it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.05it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 15.98it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.94it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.87it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.78it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.77it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.61it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.62it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.12it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.27it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.22it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.98it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.36it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.64it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.03it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.36it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.41it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.52it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.88it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.29it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.43it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.43it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.76it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.36it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.07it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.87it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.74it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.59it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.59it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.62it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.62it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.45it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.27it/s]\u001b[A\n",
      "                                                   A\n",
      " 50%|█████     | 1100/2195 [03:31<02:09,  8.46it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.98it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900] due to args.save_total_limit\n",
      " 55%|█████▍    | 1200/2195 [03:43<01:53,  8.76it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.72it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.63it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.91it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.86it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.14it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.74it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.46it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.23it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.10it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.00it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.96it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.90it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.92it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.83it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.72it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.28it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.42it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.33it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.03it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.64it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.14it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.44it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.62it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.59it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.71it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.96it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.28it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.41it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.38it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.76it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.35it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.07it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.91it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.77it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.54it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.45it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.42it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.42it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.43it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.47it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.34it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.14it/s]\u001b[A\n",
      "                                                   A\n",
      " 55%|█████▍    | 1200/2195 [03:49<01:53,  8.76it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.87it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000] due to args.save_total_limit\n",
      " 59%|█████▉    | 1300/2195 [04:02<01:45,  8.51it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.68it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.49it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.71it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.62it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 16.93it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.56it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.30it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.11it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.03it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.93it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.89it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.79it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.62it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.67it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.18it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.39it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.28it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.84it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.46it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.91it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.33it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.56it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.64it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.77it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.05it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.26it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.28it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.27it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.70it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.28it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.06it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.93it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.83it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.69it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.53it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.53it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.54it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.54it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.40it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.22it/s]\u001b[A\n",
      "                                                   A\n",
      " 59%|█████▉    | 1300/2195 [04:09<01:45,  8.51it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.99it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100] due to args.save_total_limit\n",
      " 64%|██████▍   | 1400/2195 [04:22<01:34,  8.41it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.13it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.17it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.55it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.56it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 16.90it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.48it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.19it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.00it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 15.87it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.77it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:05, 15.70it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.64it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.65it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.69it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.49it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.20it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.37it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.23it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.97it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.55it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.79it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.04it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.15it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.40it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.61it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.94it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.28it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.44it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.36it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.63it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.25it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 10.97it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.85it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.76it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.73it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.64it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:06<00:01, 10.55it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.47it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.50it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.31it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.21it/s]\u001b[A\n",
      "                                                   A\n",
      " 64%|██████▍   | 1400/2195 [04:29<01:34,  8.41it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.93it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200] due to args.save_total_limit\n",
      " 68%|██████▊   | 1500/2195 [04:42<01:19,  8.74it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.01it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.78it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.04it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.92it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.29it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.79it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.52it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.25it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.00it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.88it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.82it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.74it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.57it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.64it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.61it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.24it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.41it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.42it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.02it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.70it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.11it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.31it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.48it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.48it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.67it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.09it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.41it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.53it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.46it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.82it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.39it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.12it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.91it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.78it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.64it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.63it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.63it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.59it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.56it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.56it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.45it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.29it/s]\u001b[A\n",
      "                                                   A\n",
      " 68%|██████▊   | 1500/2195 [04:48<01:19,  8.74it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.04it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300] due to args.save_total_limit\n",
      " 73%|███████▎  | 1600/2195 [05:00<01:00,  9.78it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.87it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.51it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.88it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.80it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.12it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.69it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.41it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.19it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.06it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.97it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.91it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.71it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.66it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.69it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.15it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.23it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.20it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.94it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.51it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.95it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.18it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.40it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.54it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.67it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.99it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.28it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.43it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.17it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.65it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.34it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.10it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.92it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.81it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.58it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.59it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.55it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.56it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.47it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.38it/s]\u001b[A\n",
      "                                                   A\n",
      " 73%|███████▎  | 1600/2195 [05:07<01:00,  9.78it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.14it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400] due to args.save_total_limit\n",
      " 77%|███████▋  | 1700/2195 [05:20<00:52,  9.39it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.00it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.84it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.07it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.95it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.29it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.86it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.56it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.29it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.18it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.09it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.05it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.95it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.80it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.77it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.47it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.68it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.60it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.24it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.80it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.13it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.46it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.73it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.85it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.87it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.05it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.40it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.56it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.46it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.81it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.43it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.18it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.94it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.68it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.55it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.50it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.50it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.53it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.52it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.51it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.42it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.26it/s]\u001b[A\n",
      "                                                   A\n",
      " 77%|███████▋  | 1700/2195 [05:27<00:52,  9.39it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.97it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500] due to args.save_total_limit\n",
      " 82%|████████▏ | 1800/2195 [05:40<00:42,  9.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.66it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.64it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.86it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.82it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.14it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.69it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.37it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.16it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.02it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.98it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.94it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.92it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.85it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.91it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.91it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.51it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.68it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.53it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.26it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.71it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.12it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.13it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.31it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.33it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.44it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.74it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.23it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.45it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.34it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.70it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.30it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.05it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.89it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.77it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.44it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.47it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.44it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.43it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.27it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.12it/s]\u001b[A\n",
      "                                                   A\n",
      " 82%|████████▏ | 1800/2195 [05:46<00:42,  9.21it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.86it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600] due to args.save_total_limit\n",
      " 87%|████████▋ | 1900/2195 [05:58<00:34,  8.48it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 22.41it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:05, 19.18it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.03it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.27it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 16.79it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.46it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.21it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.09it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 15.95it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.91it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.87it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.80it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.76it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.74it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.67it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.35it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.52it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.34it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:02<00:03, 18.50it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:02<00:03, 18.62it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:02<00:02, 19.34it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:02<00:02, 19.87it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:02<00:02, 20.17it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:03<00:02, 20.34it/s]\u001b[A\n",
      " 57%|█████▋    | 58/102 [00:03<00:02, 20.50it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:03<00:01, 20.66it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:03<00:02, 17.36it/s]\u001b[A\n",
      " 65%|██████▍   | 66/102 [00:03<00:02, 14.53it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:04<00:02, 13.02it/s]\u001b[A\n",
      " 69%|██████▊   | 70/102 [00:04<00:02, 12.17it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:04<00:02, 11.56it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:04<00:02, 11.12it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:04<00:02, 10.67it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:04<00:02, 10.56it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:05<00:02, 10.56it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:05<00:01, 10.54it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:05<00:01, 10.52it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:05<00:01, 10.57it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:05<00:01, 10.59it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:06<00:01, 10.51it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:06<00:00, 10.52it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:06<00:00, 10.55it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:06<00:00, 12.43it/s]\u001b[A\n",
      "                                                   A\n",
      " 87%|████████▋ | 1900/2195 [06:05<00:34,  8.48it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.23it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700] due to args.save_total_limit\n",
      " 91%|█████████ | 2000/2195 [06:19<00:23,  8.31it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.80it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.60it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.93it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.90it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.27it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.70it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.46it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.25it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.09it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.99it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.88it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.79it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.78it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.35it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 15.62it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 16.88it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 17.94it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 18.82it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.40it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 19.89it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.34it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.67it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.75it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.92it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.14it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.38it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.50it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.54it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.69it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.27it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.07it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.89it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.78it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.69it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.49it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.41it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.37it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.45it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.18it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.11it/s]\u001b[A\n",
      "                                                   A\n",
      " 91%|█████████ | 2000/2195 [06:26<00:23,  8.31it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.91it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800] due to args.save_total_limit\n",
      " 96%|█████████▌| 2100/2195 [06:38<00:10,  8.66it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.77it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.62it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.96it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.96it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.32it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.73it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.45it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.23it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.13it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.96it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.85it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.82it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.86it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.83it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.66it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.27it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.43it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.39it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.06it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.62it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.06it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.42it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.61it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.71it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.81it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.03it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.38it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.58it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.57it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.86it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.43it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.96it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:05<00:02, 10.78it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.69it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.69it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.63it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.58it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.44it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.34it/s]\u001b[A\n",
      "                                                   A\n",
      " 96%|█████████▌| 2100/2195 [06:45<00:10,  8.66it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.05it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900] due to args.save_total_limit\n",
      "100%|█████████▉| 2194/2195 [06:56<00:00,  9.12it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000 (score: 0.1528051495552063).\n",
      "100%|██████████| 2195/2195 [06:57<00:00,  5.26it/s]\n",
      "Saving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_0\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_0/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_0/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_0/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_0/special_tokens_map.json\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: id, chunk_tags, pos_tags, tokens, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3453\n",
      "  Batch size = 8\n",
      "100%|██████████| 432/432 [00:09<00:00, 45.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS_FILE: bert_finetune-0.results\n",
      "{'loss': 1.421, 'learning_rate': 0.00045454545454545455, 'epoch': 0.23}\n",
      "{'eval_loss': 0.6909339427947998, 'eval_runtime': 6.8031, 'eval_samples_per_second': 477.724, 'eval_steps_per_second': 14.993, 'epoch': 0.23}\n",
      "{'loss': 0.4146, 'learning_rate': 0.0009090909090909091, 'epoch': 0.46}\n",
      "{'eval_loss': 0.35382625460624695, 'eval_runtime': 6.8713, 'eval_samples_per_second': 472.983, 'eval_steps_per_second': 14.844, 'epoch': 0.46}\n",
      "{'loss': 0.2581, 'learning_rate': 0.0009594936708860759, 'epoch': 0.68}\n",
      "{'eval_loss': 0.25817614793777466, 'eval_runtime': 6.8126, 'eval_samples_per_second': 477.054, 'eval_steps_per_second': 14.972, 'epoch': 0.68}\n",
      "{'loss': 0.221, 'learning_rate': 0.0009088607594936709, 'epoch': 0.91}\n",
      "{'eval_loss': 0.22257205843925476, 'eval_runtime': 6.8535, 'eval_samples_per_second': 474.207, 'eval_steps_per_second': 14.883, 'epoch': 0.91}\n",
      "{'loss': 0.2023, 'learning_rate': 0.0008582278481012659, 'epoch': 1.14}\n",
      "{'eval_loss': 0.20354633033275604, 'eval_runtime': 6.8225, 'eval_samples_per_second': 476.362, 'eval_steps_per_second': 14.95, 'epoch': 1.14}\n",
      "{'loss': 0.174, 'learning_rate': 0.0008075949367088608, 'epoch': 1.37}\n",
      "{'eval_loss': 0.19229169189929962, 'eval_runtime': 6.8863, 'eval_samples_per_second': 471.951, 'eval_steps_per_second': 14.812, 'epoch': 1.37}\n",
      "{'loss': 0.1694, 'learning_rate': 0.0007569620253164558, 'epoch': 1.59}\n",
      "{'eval_loss': 0.18498001992702484, 'eval_runtime': 6.8966, 'eval_samples_per_second': 471.246, 'eval_steps_per_second': 14.79, 'epoch': 1.59}\n",
      "{'loss': 0.1695, 'learning_rate': 0.0007063291139240506, 'epoch': 1.82}\n",
      "{'eval_loss': 0.17559599876403809, 'eval_runtime': 6.8702, 'eval_samples_per_second': 473.059, 'eval_steps_per_second': 14.847, 'epoch': 1.82}\n",
      "{'loss': 0.1622, 'learning_rate': 0.0006556962025316456, 'epoch': 2.05}\n",
      "{'eval_loss': 0.17333030700683594, 'eval_runtime': 6.8692, 'eval_samples_per_second': 473.129, 'eval_steps_per_second': 14.849, 'epoch': 2.05}\n",
      "{'loss': 0.1606, 'learning_rate': 0.0006050632911392405, 'epoch': 2.28}\n",
      "{'eval_loss': 0.1702708601951599, 'eval_runtime': 6.9072, 'eval_samples_per_second': 470.526, 'eval_steps_per_second': 14.767, 'epoch': 2.28}\n",
      "{'loss': 0.156, 'learning_rate': 0.0005544303797468354, 'epoch': 2.51}\n",
      "{'eval_loss': 0.16581594944000244, 'eval_runtime': 6.8941, 'eval_samples_per_second': 471.421, 'eval_steps_per_second': 14.795, 'epoch': 2.51}\n",
      "{'loss': 0.1562, 'learning_rate': 0.0005037974683544304, 'epoch': 2.73}\n",
      "{'eval_loss': 0.1622285544872284, 'eval_runtime': 6.8849, 'eval_samples_per_second': 472.048, 'eval_steps_per_second': 14.815, 'epoch': 2.73}\n",
      "{'loss': 0.1442, 'learning_rate': 0.0004531645569620253, 'epoch': 2.96}\n",
      "{'eval_loss': 0.16073279082775116, 'eval_runtime': 6.8841, 'eval_samples_per_second': 472.1, 'eval_steps_per_second': 14.817, 'epoch': 2.96}\n",
      "{'loss': 0.1483, 'learning_rate': 0.00040253164556962025, 'epoch': 3.19}\n",
      "{'eval_loss': 0.15798507630825043, 'eval_runtime': 6.9117, 'eval_samples_per_second': 470.214, 'eval_steps_per_second': 14.757, 'epoch': 3.19}\n",
      "{'loss': 0.1508, 'learning_rate': 0.0003518987341772152, 'epoch': 3.42}\n",
      "{'eval_loss': 0.15725493431091309, 'eval_runtime': 6.8571, 'eval_samples_per_second': 473.964, 'eval_steps_per_second': 14.875, 'epoch': 3.42}\n",
      "{'loss': 0.1466, 'learning_rate': 0.0003012658227848101, 'epoch': 3.64}\n",
      "{'eval_loss': 0.15575724840164185, 'eval_runtime': 6.8711, 'eval_samples_per_second': 472.998, 'eval_steps_per_second': 14.845, 'epoch': 3.64}\n",
      "{'loss': 0.1467, 'learning_rate': 0.00025063291139240505, 'epoch': 3.87}\n",
      "{'eval_loss': 0.15493889153003693, 'eval_runtime': 6.8448, 'eval_samples_per_second': 474.812, 'eval_steps_per_second': 14.902, 'epoch': 3.87}\n",
      "{'loss': 0.1409, 'learning_rate': 0.0002, 'epoch': 4.1}\n",
      "{'eval_loss': 0.15403877198696136, 'eval_runtime': 6.8874, 'eval_samples_per_second': 471.874, 'eval_steps_per_second': 14.81, 'epoch': 4.1}\n",
      "{'loss': 0.1421, 'learning_rate': 0.00014936708860759494, 'epoch': 4.33}\n",
      "{'eval_loss': 0.15352754294872284, 'eval_runtime': 6.9344, 'eval_samples_per_second': 468.676, 'eval_steps_per_second': 14.709, 'epoch': 4.33}\n",
      "{'loss': 0.15, 'learning_rate': 9.873417721518988e-05, 'epoch': 4.56}\n",
      "{'eval_loss': 0.1528051495552063, 'eval_runtime': 6.8891, 'eval_samples_per_second': 471.762, 'eval_steps_per_second': 14.806, 'epoch': 4.56}\n",
      "{'loss': 0.1344, 'learning_rate': 4.810126582278481e-05, 'epoch': 4.78}\n",
      "{'eval_loss': 0.1529323011636734, 'eval_runtime': 6.8367, 'eval_samples_per_second': 475.375, 'eval_steps_per_second': 14.919, 'epoch': 4.78}\n",
      "{'train_runtime': 417.2637, 'train_samples_per_second': 168.251, 'train_steps_per_second': 5.26, 'train_loss': 0.23279039256936596, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:11<00:00, 38.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --model bert --finetune_mode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (../conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n",
      "100%|██████████| 15/15 [00:01<00:00, 10.04ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 12.18ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.52ba/s]\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2195\n",
      "  5%|▍         | 100/2195 [00:32<09:59,  3.50it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.09it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.88it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.08it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.03it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 16.83it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.39it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.31it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.23it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.17it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.08it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.02it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.06it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.05it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.00it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.58it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.63it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.61it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.38it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.95it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.34it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.01it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.31it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.58it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.78it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.19it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.55it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.74it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.63it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.04it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.60it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.36it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.18it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 11.03it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.66it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.64it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.60it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.63it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.54it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.43it/s]\u001b[A\n",
      "                                                  [A\n",
      "  5%|▍         | 100/2195 [00:39<09:59,  3.50it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.16it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100] due to args.save_total_limit\n",
      "  9%|▉         | 200/2195 [01:14<10:15,  3.24it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.32it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.98it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.26it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.13it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.41it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.97it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.66it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.47it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.38it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.20it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.09it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.02it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.96it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.52it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.38it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.02it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.33it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.29it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.05it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.69it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.19it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.46it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.70it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.88it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.99it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.34it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.63it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.74it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.26it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.78it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.43it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.15it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.99it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.91it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.88it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.84it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.81it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.78it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.70it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.41it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.34it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.25it/s]\u001b[A\n",
      "                                                  [A\n",
      "  9%|▉         | 200/2195 [01:21<10:15,  3.24it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.00it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_0] due to args.save_total_limit\n",
      " 14%|█▎        | 300/2195 [01:54<09:29,  3.33it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.15it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 21.01it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.25it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.14it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.37it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.84it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.55it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.40it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.16it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.11it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.82it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.28it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.54it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.71it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.45it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.68it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.75it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.52it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.13it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.58it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.82it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 21.01it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.15it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.27it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:01, 19.52it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.76it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.56it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.37it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.85it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.54it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.31it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 11.05it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.95it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.86it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.85it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.81it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.82it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.49it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.56it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.49it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.39it/s]\u001b[A\n",
      "                                                  [A\n",
      " 14%|█▎        | 300/2195 [02:01<09:29,  3.33it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.16it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100] due to args.save_total_limit\n",
      " 18%|█▊        | 400/2195 [02:34<09:54,  3.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.59it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.51it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.83it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.81it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.12it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.67it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.40it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.24it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.12it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.97it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.94it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.70it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.31it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.43it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.53it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.23it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.40it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.41it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.20it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.79it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.24it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.62it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:03<00:02, 20.86it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.96it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.93it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.16it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.47it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.62it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.60it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.99it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.52it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.29it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.11it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 11.00it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.93it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.86it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.82it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.80it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.76it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.74it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.70it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.57it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.49it/s]\u001b[A\n",
      "                                                  [A\n",
      " 18%|█▊        | 400/2195 [02:41<09:54,  3.02it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.27it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200] due to args.save_total_limit\n",
      " 23%|██▎       | 500/2195 [03:16<09:17,  3.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.13it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.92it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.19it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.11it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.38it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.93it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.63it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.45it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.26it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.15it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.12it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.06it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.98it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.94it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.91it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.47it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.70it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.65it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.37it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.86it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.05it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.37it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.59it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.76it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.86it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.17it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.33it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.59it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.57it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.98it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.60it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.33it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.92it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.80it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.79it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.73it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.70it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.53it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.35it/s]\u001b[A\n",
      "                                                  [A\n",
      " 23%|██▎       | 500/2195 [03:22<09:17,  3.04it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.09it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300] due to args.save_total_limit\n",
      " 27%|██▋       | 600/2195 [03:57<08:43,  3.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.25it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.93it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.24it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.13it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.44it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.98it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.72it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.59it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.40it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.33it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.30it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.22it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.18it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.12it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.12it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.79it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.97it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.92it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.65it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.18it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.47it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.75it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.86it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.90it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.14it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.42it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.66it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.75it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:03<00:02, 12.67it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.00it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.60it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.31it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.13it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.99it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.92it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.84it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.76it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.67it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.67it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.68it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.56it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.45it/s]\u001b[A\n",
      "                                                  [A\n",
      " 27%|██▋       | 600/2195 [04:03<08:43,  3.05it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.19it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400] due to args.save_total_limit\n",
      " 32%|███▏      | 700/2195 [04:37<08:15,  3.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.15it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.96it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.04it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.94it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.30it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.94it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.67it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.35it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.24it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.21it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.13it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.99it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.94it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.93it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.88it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.45it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.60it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.52it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.24it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.76it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.13it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.43it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.68it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.75it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.88it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.19it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.51it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.43it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.47it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.86it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.44it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.16it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.02it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.93it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.88it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.86it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.79it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.76it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.63it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.67it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.58it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.49it/s]\u001b[A\n",
      "                                                  [A\n",
      " 32%|███▏      | 700/2195 [04:44<08:15,  3.02it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.31it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500] due to args.save_total_limit\n",
      " 36%|███▋      | 800/2195 [05:18<07:44,  3.00it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.10it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.96it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.19it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.11it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.38it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.98it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.76it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.58it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.46it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.28it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.27it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.18it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.14it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.77it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.62it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.31it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.55it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.60it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.42it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.02it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.52it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.76it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.95it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.12it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.27it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:01, 19.57it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.70it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.84it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:03<00:02, 12.55it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.76it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.35it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.02it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.93it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.84it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.80it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.72it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.65it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.60it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.36it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.23it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.17it/s]\u001b[A\n",
      "                                                  [A\n",
      " 36%|███▋      | 800/2195 [05:25<07:44,  3.00it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.96it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600] due to args.save_total_limit\n",
      " 41%|████      | 900/2195 [06:01<06:29,  3.32it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.70it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.80it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.13it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.15it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.34it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.93it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.65it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.49it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.27it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.17it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.86it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.87it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.84it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.86it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.91it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.54it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.70it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.61it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.25it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.89it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.32it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.58it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.81it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.92it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.97it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.29it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.48it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.68it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.56it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.97it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.57it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.30it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.13it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.97it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.86it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.77it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.72it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.61it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.58it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.62it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.54it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.41it/s]\u001b[A\n",
      "                                                  [A\n",
      " 41%|████      | 900/2195 [06:08<06:29,  3.32it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.14it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700] due to args.save_total_limit\n",
      " 46%|████▌     | 1000/2195 [06:42<06:20,  3.14it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 22.90it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.25it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.82it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.85it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.26it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.82it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.53it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.30it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.21it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.13it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.13it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.98it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.98it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.97it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.96it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.55it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:02<00:03, 17.36it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:02<00:03, 18.35it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:02<00:03, 19.12it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:02<00:02, 19.66it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:02<00:02, 20.19it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:02<00:02, 20.55it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:02<00:02, 20.74it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:03<00:02, 20.79it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:03<00:02, 20.79it/s]\u001b[A\n",
      " 61%|██████    | 62/102 [00:03<00:01, 20.81it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 16.25it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 14.05it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.83it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.06it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.59it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.30it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.07it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.89it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.82it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.76it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.72it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.64it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.61it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.53it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.42it/s]\u001b[A\n",
      "                                                   A\n",
      " 46%|████▌     | 1000/2195 [06:49<06:20,  3.14it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.22it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800] due to args.save_total_limit\n",
      " 50%|█████     | 1100/2195 [07:24<05:59,  3.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.31it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.87it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.09it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.03it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.29it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.83it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.61it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.40it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.29it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.17it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.13it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.11it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.89it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.85it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.38it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.45it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.41it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.08it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.65it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.11it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.43it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.68it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.58it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.65it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.99it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.43it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.59it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.51it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.87it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.48it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.22it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.98it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.84it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.76it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.63it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.64it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.63it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.49it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.32it/s]\u001b[A\n",
      "                                                   A\n",
      " 50%|█████     | 1100/2195 [07:30<05:59,  3.04it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.06it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900] due to args.save_total_limit\n",
      " 55%|█████▍    | 1200/2195 [08:04<05:18,  3.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.07it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.82it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.15it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.08it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.45it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 17.00it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.63it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.38it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 15.80it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.64it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:05, 15.71it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.81it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.85it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.89it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.88it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.52it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.72it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.65it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.36it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.88it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.31it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.55it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.74it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.82it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.78it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.77it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.38it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.63it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.57it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.91it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.51it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.31it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 11.05it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.96it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.91it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.82it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.69it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.68it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.67it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.52it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.39it/s]\u001b[A\n",
      "                                                   A\n",
      " 55%|█████▍    | 1200/2195 [08:11<05:18,  3.13it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.15it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000] due to args.save_total_limit\n",
      " 59%|█████▉    | 1300/2195 [08:46<04:52,  3.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.56it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 21.20it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.42it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.25it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.51it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 17.07it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.71it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.37it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.29it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.23it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.23it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.15it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.05it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.13it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.78it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.96it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.90it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.68it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.14it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.38it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.74it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 21.01it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.13it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.17it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.36it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.66it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.79it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:03<00:02, 12.71it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.07it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.67it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.35it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.07it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.97it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.92it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.86it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.83it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.84it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.81it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.72it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.63it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.55it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.44it/s]\u001b[A\n",
      "                                                   A\n",
      " 59%|█████▉    | 1300/2195 [08:52<04:52,  3.06it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.23it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100] due to args.save_total_limit\n",
      " 64%|██████▍   | 1400/2195 [09:26<04:20,  3.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.41it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 21.13it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.29it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.15it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.38it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.90it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.58it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.42it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.31it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.28it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.23it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.15it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.10it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.10it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.73it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.90it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.77it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.53it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.01it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.40it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.80it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 21.05it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.12it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.18it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.50it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.71it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.78it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:03<00:02, 12.66it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.03it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.64it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.37it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.18it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 11.06it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.96it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.83it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.64it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.66it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.63it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.53it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.42it/s]\u001b[A\n",
      "                                                   A\n",
      " 64%|██████▍   | 1400/2195 [09:33<04:20,  3.05it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.15it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200] due to args.save_total_limit\n",
      " 68%|██████▊   | 1500/2195 [10:07<03:41,  3.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.05it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.87it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.11it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.01it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.35it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.88it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.61it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.36it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.18it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.00it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.98it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.99it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.96it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.95it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.92it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.54it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.70it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.53it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.16it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.77it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.20it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.54it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.79it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.90it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.92it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.16it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.50it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.70it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.65it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.97it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.57it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.31it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.09it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.95it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.86it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.81it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.77it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.70it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.66it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.54it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.41it/s]\u001b[A\n",
      "                                                   A\n",
      " 68%|██████▊   | 1500/2195 [10:14<03:41,  3.13it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.20it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400] due to args.save_total_limit\n",
      " 73%|███████▎  | 1600/2195 [10:50<02:46,  3.57it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.93it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.73it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.00it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.97it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.20it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.74it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.47it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.26it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.12it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 15.94it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 15.82it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 15.82it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 15.73it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.80it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 15.88it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:04, 16.50it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.69it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.62it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.29it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.78it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.18it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.60it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.84it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.04it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.14it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.33it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.67it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.78it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.71it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.05it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.61it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.32it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.10it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.91it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.83it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.78it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.75it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.73it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.65it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.62it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.51it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.42it/s]\u001b[A\n",
      "                                                   A\n",
      " 73%|███████▎  | 1600/2195 [10:56<02:46,  3.57it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.16it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500] due to args.save_total_limit\n",
      " 77%|███████▋  | 1700/2195 [11:30<02:23,  3.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.26it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.92it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.13it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.03it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.40it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.95it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.64it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.41it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.33it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.22it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.19it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.11it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.10it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.08it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.10it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.67it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.79it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.75it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.45it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.01it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.27it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.48it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.66it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.84it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.70it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 18.75it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.31it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.61it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.62it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.98it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.59it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.32it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 11.01it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.91it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.82it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.82it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.72it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.71it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.73it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.64it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.52it/s]\u001b[A\n",
      "                                                   A\n",
      " 77%|███████▋  | 1700/2195 [11:37<02:23,  3.44it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.27it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300] due to args.save_total_limit\n",
      " 82%|████████▏ | 1800/2195 [12:12<02:15,  2.91it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:05, 19.71it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:05, 16.93it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:06, 15.57it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:06, 14.78it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:06, 14.24it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:06, 13.66it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:01<00:06, 13.50it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:06, 13.39it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:06, 13.18it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:06, 13.19it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:05, 13.19it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:05, 13.27it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:02<00:05, 12.91it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:02<00:05, 12.98it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:02<00:05, 13.06it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:02<00:05, 13.76it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:02<00:04, 14.93it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:02<00:04, 15.42it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:04, 15.71it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:02<00:03, 16.08it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:03<00:03, 16.34it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:03<00:03, 16.45it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:03<00:03, 16.63it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:03<00:03, 16.55it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:03<00:03, 16.61it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:03<00:02, 16.60it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:03<00:02, 16.67it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 16.70it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:03<00:02, 16.76it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:04<00:02, 16.94it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:04<00:02, 15.12it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:04<00:02, 12.49it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:04<00:03, 11.20it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:03, 10.45it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:05<00:03,  9.95it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:05<00:03,  9.66it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:05<00:02,  9.49it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:05<00:02,  9.33it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:05<00:02,  9.25it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:05<00:02,  9.19it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:06<00:02,  9.08it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:06<00:02,  9.28it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:06<00:02,  9.03it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:06<00:02,  9.00it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:06<00:02,  9.01it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:06<00:01,  9.11it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:06<00:01,  9.07it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:06<00:01,  9.04it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:06<00:01,  9.05it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:07<00:01,  9.07it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:07<00:01,  9.04it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:07<00:01,  9.01it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:07<00:01,  9.06it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:07<00:01,  9.01it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:07<00:01,  9.00it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:07<00:00,  9.14it/s]\u001b[A\n",
      " 94%|█████████▍| 96/102 [00:07<00:00, 10.83it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:07<00:00, 12.30it/s]\u001b[A\n",
      "                                                   A\n",
      " 82%|████████▏ | 1800/2195 [12:20<02:15,  2.91it/s]\n",
      "100%|██████████| 102/102 [00:08<00:00, 13.95it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600] due to args.save_total_limit\n",
      " 87%|████████▋ | 1900/2195 [12:58<01:36,  3.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.31it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.98it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.04it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 17.86it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.30it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.85it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.52it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.40it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.21it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:05, 16.14it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.08it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.13it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.01it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 15.97it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.00it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.67it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.92it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.84it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.53it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.93it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.39it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.60it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.86it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.03it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.08it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.32it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.65it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.75it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:03<00:02, 12.69it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 12.03it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.60it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.35it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.15it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.98it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.83it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.77it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.72it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.70it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.65it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.65it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.51it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.39it/s]\u001b[A\n",
      "                                                   A\n",
      " 87%|████████▋ | 1900/2195 [13:04<01:36,  3.05it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.09it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700] due to args.save_total_limit\n",
      " 91%|█████████ | 2000/2195 [13:38<01:03,  3.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 23.40it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 20.56it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:05, 18.97it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.04it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.34it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 16.91it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.63it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:01<00:05, 16.48it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.32it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.26it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.22it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.21it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.07it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.05it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.64it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 17.78it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 18.77it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.48it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 19.87it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.21it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.52it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 20.71it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 20.80it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:02, 20.89it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:02, 19.14it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.40it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.54it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:04<00:02, 12.53it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.86it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.42it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.14it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 10.98it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.89it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.77it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.68it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.62it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.60it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.58it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.38it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.28it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.18it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.07it/s]\u001b[A\n",
      "                                                   A\n",
      " 91%|█████████ | 2000/2195 [13:45<01:03,  3.05it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 14.90it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800] due to args.save_total_limit\n",
      " 96%|█████████▌| 2100/2195 [14:18<00:29,  3.27it/s]The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/102 [00:00<00:04, 24.43it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:04, 21.14it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:04, 19.31it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:05, 18.21it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:05, 17.58it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:05, 17.11it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:05, 16.83it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:05, 16.59it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:01<00:05, 16.49it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:01<00:04, 16.42it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:01<00:04, 16.36it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:01<00:04, 16.31it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:01<00:04, 16.27it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:01<00:04, 16.26it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:04, 16.25it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:04, 16.88it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:02<00:03, 18.10it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:02<00:03, 19.04it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:02<00:03, 19.78it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:02<00:02, 20.27it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:02<00:02, 20.71it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:02<00:02, 20.97it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:02<00:02, 21.15it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:03<00:02, 21.34it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:03<00:01, 21.45it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:03<00:01, 19.64it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:03<00:02, 15.83it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:03<00:02, 13.86it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:03<00:02, 12.73it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:04<00:02, 11.99it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:04<00:02, 11.54it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:04<00:02, 11.26it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:04<00:02, 11.10it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:04<00:02, 10.94it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:05<00:01, 10.84it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:05<00:01, 10.78it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:05<00:01, 10.76it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:05<00:01, 10.74it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:05<00:01, 10.71it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:06<00:01, 10.69it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:06<00:00, 10.65it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:06<00:00, 11.50it/s]\u001b[A\n",
      " 96%|█████████▌| 98/102 [00:06<00:00, 13.39it/s]\u001b[A\n",
      "                                                   A\n",
      " 96%|█████████▌| 2100/2195 [14:25<00:29,  3.27it/s]\n",
      "100%|██████████| 102/102 [00:06<00:00, 15.14it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900] due to args.save_total_limit\n",
      "100%|██████████| 2195/2195 [14:56<00:00,  3.47it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100 (score: 0.04019718989729881).\n",
      "100%|██████████| 2195/2195 [14:57<00:00,  2.45it/s]\n",
      "Saving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_1\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_1/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_1/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_1/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_1/special_tokens_map.json\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, id, pos_tags, chunk_tags, ner_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3453\n",
      "  Batch size = 8\n",
      "100%|█████████▉| 430/432 [00:09<00:00, 44.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS_FILE: bert_finetune-1.results\n",
      "{'loss': 1.364, 'learning_rate': 4.5454545454545455e-06, 'epoch': 0.23}\n",
      "{'eval_loss': 1.362937331199646, 'eval_runtime': 6.804, 'eval_samples_per_second': 477.663, 'eval_steps_per_second': 14.991, 'epoch': 0.23}\n",
      "{'loss': 0.3418, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.46}\n",
      "{'eval_loss': 0.3745158016681671, 'eval_runtime': 6.8102, 'eval_samples_per_second': 477.223, 'eval_steps_per_second': 14.977, 'epoch': 0.46}\n",
      "{'loss': 0.1493, 'learning_rate': 9.59493670886076e-06, 'epoch': 0.68}\n",
      "{'eval_loss': 0.16732682287693024, 'eval_runtime': 6.7695, 'eval_samples_per_second': 480.092, 'eval_steps_per_second': 15.068, 'epoch': 0.68}\n",
      "{'loss': 0.1065, 'learning_rate': 9.08860759493671e-06, 'epoch': 0.91}\n",
      "{'eval_loss': 0.10588031262159348, 'eval_runtime': 6.7968, 'eval_samples_per_second': 478.163, 'eval_steps_per_second': 15.007, 'epoch': 0.91}\n",
      "{'loss': 0.0773, 'learning_rate': 8.582278481012659e-06, 'epoch': 1.14}\n",
      "{'eval_loss': 0.08454106003046036, 'eval_runtime': 6.7834, 'eval_samples_per_second': 479.11, 'eval_steps_per_second': 15.037, 'epoch': 1.14}\n",
      "{'loss': 0.058, 'learning_rate': 8.075949367088608e-06, 'epoch': 1.37}\n",
      "{'eval_loss': 0.06846386939287186, 'eval_runtime': 6.7355, 'eval_samples_per_second': 482.517, 'eval_steps_per_second': 15.144, 'epoch': 1.37}\n",
      "{'loss': 0.0563, 'learning_rate': 7.569620253164558e-06, 'epoch': 1.59}\n",
      "{'eval_loss': 0.06164003163576126, 'eval_runtime': 6.7863, 'eval_samples_per_second': 478.903, 'eval_steps_per_second': 15.03, 'epoch': 1.59}\n",
      "{'loss': 0.054, 'learning_rate': 7.0632911392405065e-06, 'epoch': 1.82}\n",
      "{'eval_loss': 0.05303317680954933, 'eval_runtime': 6.7904, 'eval_samples_per_second': 478.617, 'eval_steps_per_second': 15.021, 'epoch': 1.82}\n",
      "{'loss': 0.0446, 'learning_rate': 6.5569620253164564e-06, 'epoch': 2.05}\n",
      "{'eval_loss': 0.04980198293924332, 'eval_runtime': 6.7833, 'eval_samples_per_second': 479.119, 'eval_steps_per_second': 15.037, 'epoch': 2.05}\n",
      "{'loss': 0.0366, 'learning_rate': 6.050632911392406e-06, 'epoch': 2.28}\n",
      "{'eval_loss': 0.04801257327198982, 'eval_runtime': 6.8003, 'eval_samples_per_second': 477.921, 'eval_steps_per_second': 14.999, 'epoch': 2.28}\n",
      "{'loss': 0.0336, 'learning_rate': 5.544303797468355e-06, 'epoch': 2.51}\n",
      "{'eval_loss': 0.045579880475997925, 'eval_runtime': 6.8176, 'eval_samples_per_second': 476.71, 'eval_steps_per_second': 14.961, 'epoch': 2.51}\n",
      "{'loss': 0.0355, 'learning_rate': 5.037974683544305e-06, 'epoch': 2.73}\n",
      "{'eval_loss': 0.04484239220619202, 'eval_runtime': 6.7927, 'eval_samples_per_second': 478.452, 'eval_steps_per_second': 15.016, 'epoch': 2.73}\n",
      "{'loss': 0.0308, 'learning_rate': 4.531645569620253e-06, 'epoch': 2.96}\n",
      "{'eval_loss': 0.041953135281801224, 'eval_runtime': 6.7305, 'eval_samples_per_second': 482.879, 'eval_steps_per_second': 15.155, 'epoch': 2.96}\n",
      "{'loss': 0.0261, 'learning_rate': 4.025316455696203e-06, 'epoch': 3.19}\n",
      "{'eval_loss': 0.04277519881725311, 'eval_runtime': 6.7401, 'eval_samples_per_second': 482.188, 'eval_steps_per_second': 15.133, 'epoch': 3.19}\n",
      "{'loss': 0.026, 'learning_rate': 3.518987341772152e-06, 'epoch': 3.42}\n",
      "{'eval_loss': 0.04303500056266785, 'eval_runtime': 6.7787, 'eval_samples_per_second': 479.444, 'eval_steps_per_second': 15.047, 'epoch': 3.42}\n",
      "{'loss': 0.0247, 'learning_rate': 3.0126582278481016e-06, 'epoch': 3.64}\n",
      "{'eval_loss': 0.042340170592069626, 'eval_runtime': 6.7846, 'eval_samples_per_second': 479.024, 'eval_steps_per_second': 15.034, 'epoch': 3.64}\n",
      "{'loss': 0.0223, 'learning_rate': 2.5063291139240508e-06, 'epoch': 3.87}\n",
      "{'eval_loss': 0.04129180312156677, 'eval_runtime': 6.7651, 'eval_samples_per_second': 480.407, 'eval_steps_per_second': 15.077, 'epoch': 3.87}\n",
      "{'loss': 0.0218, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.1}\n",
      "{'eval_loss': 0.04084979370236397, 'eval_runtime': 8.1681, 'eval_samples_per_second': 397.889, 'eval_steps_per_second': 12.488, 'epoch': 4.1}\n",
      "{'loss': 0.0191, 'learning_rate': 1.4936708860759495e-06, 'epoch': 4.33}\n",
      "{'eval_loss': 0.04082605615258217, 'eval_runtime': 6.765, 'eval_samples_per_second': 480.416, 'eval_steps_per_second': 15.078, 'epoch': 4.33}\n",
      "{'loss': 0.0201, 'learning_rate': 9.873417721518988e-07, 'epoch': 4.56}\n",
      "{'eval_loss': 0.04041079059243202, 'eval_runtime': 6.8205, 'eval_samples_per_second': 476.506, 'eval_steps_per_second': 14.955, 'epoch': 4.56}\n",
      "{'loss': 0.0201, 'learning_rate': 4.810126582278482e-07, 'epoch': 4.78}\n",
      "{'eval_loss': 0.04019718989729881, 'eval_runtime': 6.7154, 'eval_samples_per_second': 483.965, 'eval_steps_per_second': 15.189, 'epoch': 4.78}\n",
      "{'train_runtime': 897.3134, 'train_samples_per_second': 78.239, 'train_steps_per_second': 2.446, 'train_loss': 0.11787033922851493, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:10<00:00, 40.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --model distilbert --finetune_mode 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (../conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n",
      "100%|██████████| 15/15 [00:01<00:00, 11.79ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.08ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.86ba/s]\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2195\n",
      "  5%|▍         | 100/2195 [00:06<02:06, 16.59it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 38.73it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.69it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.59it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:02, 32.33it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.54it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 30.97it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 29.78it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 30.04it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.17it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.28it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 34.40it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 35.97it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.16it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 38.06it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:01<00:01, 38.72it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:01<00:01, 32.50it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:02<00:01, 27.81it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 25.18it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 23.38it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 22.35it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.73it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 21.27it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.94it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.60it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.47it/s]\u001b[A\n",
      "                                                  A\n",
      "  5%|▍         | 100/2195 [00:10<02:06, 16.59it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 23.90it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100] due to args.save_total_limit\n",
      "  9%|▉         | 200/2195 [00:16<01:51, 17.85it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.47it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.79it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.96it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.64it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 32.05it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 31.53it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 31.13it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.77it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:02, 31.20it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 33.32it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 35.10it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 36.48it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.44it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 38.13it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.59it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.50it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.51it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.95it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.83it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.21it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.55it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.17it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 20.77it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.62it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.42it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.41it/s]\u001b[A\n",
      "                                                  A\n",
      "  9%|▉         | 200/2195 [00:20<01:51, 17.85it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.87it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-bert_finetune_1] due to args.save_total_limit\n",
      " 14%|█▎        | 300/2195 [00:26<01:50, 17.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.33it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.24it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.27it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 31.93it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.11it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 30.74it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:00<00:02, 30.45it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.16it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 29.65it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 29.68it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 31.78it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 33.21it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 34.81it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 35.68it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 36.55it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.19it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 37.71it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 33.57it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 27.89it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 24.95it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.22it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.10it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.29it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 20.90it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.62it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.44it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.30it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:03<00:00, 22.78it/s]\u001b[A\n",
      "                                                  [A\n",
      " 14%|█▎        | 300/2195 [00:30<01:50, 17.11it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 26.07it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100] due to args.save_total_limit\n",
      " 18%|█▊        | 400/2195 [00:36<01:43, 17.40it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.65it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 34.84it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.18it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.01it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.42it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 30.97it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.92it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.77it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.50it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.64it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 34.45it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:01<00:01, 35.98it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:01<00:01, 37.04it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:01<00:01, 37.68it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:01<00:01, 38.11it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:01<00:01, 38.57it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:01<00:01, 32.50it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:02<00:01, 27.55it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 24.85it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 23.35it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 22.35it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.65it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 21.22it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.89it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.62it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.54it/s]\u001b[A\n",
      "                                                  A\n",
      " 18%|█▊        | 400/2195 [00:40<01:43, 17.40it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.04it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200] due to args.save_total_limit\n",
      " 23%|██▎       | 500/2195 [00:49<01:44, 16.18it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 38.92it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.26it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.27it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 31.73it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 30.91it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.37it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.04it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 29.77it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.58it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.45it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 30.95it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 32.77it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.10it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.26it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 35.89it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 36.52it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 36.99it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.18it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.80it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.53it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.60it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.35it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.56it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.11it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.77it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.50it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.39it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.35it/s]\u001b[A\n",
      "                                                  A\n",
      " 23%|██▎       | 500/2195 [00:53<01:44, 16.18it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.67it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300] due to args.save_total_limit\n",
      " 27%|██▋       | 600/2195 [00:59<01:37, 16.37it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.81it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.94it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.76it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.28it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.29it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.74it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.31it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 29.81it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.54it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.35it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.16it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 32.99it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.61it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.72it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.48it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 36.90it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.29it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.54it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.09it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.79it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.90it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.61it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.76it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.13it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.75it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.57it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.45it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.21it/s]\u001b[A\n",
      "                                                  A\n",
      " 27%|██▋       | 600/2195 [01:03<01:37, 16.37it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.62it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400] due to args.save_total_limit\n",
      " 32%|███▏      | 700/2195 [01:10<01:32, 16.12it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.25it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.78it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.73it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.39it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.48it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.83it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.27it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 29.93it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.47it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.23it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 30.68it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 32.38it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.06it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 34.80it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 35.29it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 36.02it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 36.68it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 34.95it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.68it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.54it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.67it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.56it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.60it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 20.87it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.46it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.29it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.27it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.32it/s]\u001b[A\n",
      "                                                  A\n",
      " 32%|███▏      | 700/2195 [01:13<01:32, 16.12it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.67it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500] due to args.save_total_limit\n",
      " 36%|███▋      | 800/2195 [01:20<01:19, 17.44it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.88it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.22it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.34it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:02, 32.15it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.34it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 30.84it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 30.54it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.30it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 30.13it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 31.25it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.37it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.89it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 36.00it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.14it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.68it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.25it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.24it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.49it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 26.07it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 24.01it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.71it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:00, 22.01it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.50it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 21.08it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.85it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.65it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.56it/s]\u001b[A\n",
      "                                                  [A\n",
      " 36%|███▋      | 800/2195 [01:24<01:19, 17.44it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.12it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600] due to args.save_total_limit\n",
      " 41%|████      | 900/2195 [01:30<01:18, 16.55it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.90it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 36.40it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 34.26it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:02, 32.68it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.79it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 31.23it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.86it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.54it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.31it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.43it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 34.08it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 35.39it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 36.51it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 37.31it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.85it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 38.10it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 33.96it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 28.41it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.23it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.41it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.08it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.39it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 20.99it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.80it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.58it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.23it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:03<00:00, 22.76it/s]\u001b[A\n",
      "                                                  [A\n",
      " 41%|████      | 900/2195 [01:34<01:18, 16.55it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 26.02it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700] due to args.save_total_limit\n",
      " 46%|████▌     | 1000/2195 [01:40<01:08, 17.37it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.68it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.03it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.27it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 32.36it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 31.79it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 31.42it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 31.13it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.94it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:01, 33.14it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 34.93it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:01<00:01, 36.24it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 37.33it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 38.11it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.55it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.64it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.80it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 26.41it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 24.25it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.86it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:00, 22.00it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.58it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 21.26it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.92it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.76it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.63it/s]\u001b[A\n",
      "                                                   \n",
      " 46%|████▌     | 1000/2195 [01:44<01:08, 17.37it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.00it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800] due to args.save_total_limit\n",
      " 50%|█████     | 1100/2195 [01:50<01:05, 16.81it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 38.15it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.40it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 33.73it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 32.65it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 31.90it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 31.42it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 31.05it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:02, 31.39it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 33.55it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 35.14it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:01<00:01, 36.31it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:01<00:01, 37.00it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:01<00:01, 37.62it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:01<00:01, 37.62it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:01<00:01, 38.03it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:01<00:01, 32.21it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:02<00:01, 27.56it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.05it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.46it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.46it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.76it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.38it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 21.10it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.76it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.55it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:03<00:00, 23.06it/s]\u001b[A\n",
      "                                                   A\n",
      " 50%|█████     | 1100/2195 [01:54<01:05, 16.81it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 26.80it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900] due to args.save_total_limit\n",
      " 55%|█████▍    | 1200/2195 [02:00<00:56, 17.55it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 38.21it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.53it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.62it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:02, 32.37it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.32it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 30.81it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 30.47it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 30.36it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.37it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 32.77it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 34.54it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 36.05it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 36.99it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.89it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.45it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.57it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.70it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 26.23it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 24.17it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.91it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:00, 22.04it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.60it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 21.34it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 21.04it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.81it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.63it/s]\u001b[A\n",
      "                                                   A\n",
      " 55%|█████▍    | 1200/2195 [02:03<00:56, 17.55it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.11it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000] due to args.save_total_limit\n",
      " 59%|█████▉    | 1300/2195 [02:10<00:54, 16.51it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.97it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.11it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.82it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.52it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.63it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 31.03it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.57it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.39it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 30.29it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 31.31it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.16it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.72it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 35.85it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 36.68it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:01<00:01, 37.35it/s]\u001b[A\n",
      " 57%|█████▋    | 58/102 [00:01<00:01, 37.96it/s]\u001b[A\n",
      " 61%|██████    | 62/102 [00:01<00:01, 38.33it/s]\u001b[A\n",
      " 65%|██████▍   | 66/102 [00:02<00:01, 30.41it/s]\u001b[A\n",
      " 69%|██████▊   | 70/102 [00:02<00:01, 26.54it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 24.27it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 22.88it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 21.92it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.43it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 21.01it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.77it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.67it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.62it/s]\u001b[A\n",
      "                                                   \n",
      " 59%|█████▉    | 1300/2195 [02:14<00:54, 16.51it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.13it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100] due to args.save_total_limit\n",
      " 64%|██████▍   | 1400/2195 [02:22<00:47, 16.58it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 38.05it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 34.94it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.40it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 32.39it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 31.81it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 31.17it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.80it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:00<00:02, 30.58it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 32.08it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 34.04it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 35.59it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 36.78it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.61it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 38.06it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.39it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.31it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.54it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 26.18it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 24.21it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.99it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:00, 22.06it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.46it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 21.10it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.85it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.61it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.47it/s]\u001b[A\n",
      "                                                   \n",
      " 64%|██████▍   | 1400/2195 [02:25<00:47, 16.58it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.82it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200] due to args.save_total_limit\n",
      " 68%|██████▊   | 1500/2195 [02:32<00:40, 16.98it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.45it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 34.95it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.26it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:02, 32.00it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 31.42it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:00<00:02, 31.01it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.69it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.21it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.06it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 32.51it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.48it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 35.88it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.04it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.59it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.06it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.05it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.41it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 26.05it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 24.06it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.79it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.89it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.32it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 20.94it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.56it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.34it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.29it/s]\u001b[A\n",
      "                                                   \n",
      " 68%|██████▊   | 1500/2195 [02:35<00:40, 16.98it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.70it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300] due to args.save_total_limit\n",
      " 73%|███████▎  | 1600/2195 [02:42<00:32, 18.33it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.81it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.20it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 33.62it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 32.50it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 31.70it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:00<00:02, 31.00it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.63it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.33it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.19it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.46it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 34.08it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 35.23it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 36.38it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 37.16it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.72it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 38.05it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 33.81it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 28.22it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.30it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.53it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.40it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.60it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.07it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.69it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.46it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.27it/s]\u001b[A\n",
      " 94%|█████████▍| 96/102 [00:03<00:00, 22.44it/s]\u001b[A\n",
      "                                                   A\n",
      " 73%|███████▎  | 1600/2195 [02:45<00:32, 18.33it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.82it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400] due to args.save_total_limit\n",
      " 77%|███████▋  | 1700/2195 [02:51<00:27, 18.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 38.09it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.33it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 33.69it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 32.61it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 31.69it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:00<00:02, 31.09it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.71it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 30.30it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 31.04it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.00it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.77it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 36.15it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.32it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 38.04it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.56it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.68it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.87it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 26.21it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 24.06it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.62it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.90it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.21it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 20.79it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.54it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.42it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.30it/s]\u001b[A\n",
      "                                                   \n",
      " 77%|███████▋  | 1700/2195 [02:55<00:27, 18.02it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.72it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500] due to args.save_total_limit\n",
      " 82%|████████▏ | 1800/2195 [03:01<00:23, 16.91it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.86it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 35.06it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.33it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.25it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.59it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 31.11it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.76it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.44it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.26it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.44it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 34.25it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 35.57it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 36.68it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 37.39it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.81it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 38.14it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 34.08it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 28.36it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.46it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.67it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.54it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.65it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 20.87it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.61it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.49it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.36it/s]\u001b[A\n",
      " 94%|█████████▍| 96/102 [00:03<00:00, 22.52it/s]\u001b[A\n",
      "                                                   A\n",
      " 82%|████████▏ | 1800/2195 [03:05<00:23, 16.91it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.88it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600] due to args.save_total_limit\n",
      " 87%|████████▋ | 1900/2195 [03:11<00:17, 16.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 38.02it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.40it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 33.58it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 32.50it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 31.69it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 31.13it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.65it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 30.41it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 31.40it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.36it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 35.05it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 36.10it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 37.16it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:01<00:01, 37.83it/s]\u001b[A\n",
      " 57%|█████▋    | 58/102 [00:01<00:01, 38.05it/s]\u001b[A\n",
      " 61%|██████    | 62/102 [00:01<00:01, 38.37it/s]\u001b[A\n",
      " 65%|██████▍   | 66/102 [00:01<00:01, 30.28it/s]\u001b[A\n",
      " 69%|██████▊   | 70/102 [00:02<00:01, 26.37it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 24.23it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 22.93it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 22.16it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.62it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 21.25it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.84it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.66it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.50it/s]\u001b[A\n",
      "                                                   \n",
      " 87%|████████▋ | 1900/2195 [03:15<00:17, 16.47it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 23.93it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700] due to args.save_total_limit\n",
      " 91%|█████████ | 2000/2195 [03:21<00:11, 17.00it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.39it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.65it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.39it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.21it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.41it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.95it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.52it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.32it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.25it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 30.14it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.17it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 33.93it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 34.98it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 36.22it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 37.11it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.79it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 38.29it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 34.08it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 28.46it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.39it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.70it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.53it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.77it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.27it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.95it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.75it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.48it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:03<00:00, 22.97it/s]\u001b[A\n",
      "                                                   A\n",
      " 91%|█████████ | 2000/2195 [03:25<00:11, 17.00it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 26.30it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800] due to args.save_total_limit\n",
      " 96%|█████████▌| 2100/2195 [03:31<00:05, 17.42it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.55it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 34.94it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 33.34it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 32.06it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 31.30it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.89it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.54it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.32it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:02, 30.82it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 32.93it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 34.52it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:01<00:01, 35.72it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:01<00:01, 36.68it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:01<00:01, 37.44it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:01<00:01, 37.97it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:01<00:01, 38.31it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:01<00:01, 32.16it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:02<00:01, 27.31it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 24.72it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.14it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.14it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.26it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 20.93it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.60it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.41it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.31it/s]\u001b[A\n",
      " 94%|█████████▍| 96/102 [00:03<00:00, 22.45it/s]\u001b[A\n",
      "                                                   A\n",
      " 96%|█████████▌| 2100/2195 [03:35<00:05, 17.42it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.84it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900] due to args.save_total_limit\n",
      "100%|█████████▉| 2194/2195 [03:41<00:00, 17.62it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100 (score: 0.18925593793392181).\n",
      "100%|██████████| 2195/2195 [03:41<00:00,  9.91it/s]\n",
      "Saving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_0\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_0/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_0/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_0/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_0/special_tokens_map.json\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, chunk_tags, id, pos_tags, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3453\n",
      "  Batch size = 8\n",
      " 99%|█████████▉| 428/432 [00:05<00:00, 82.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS_FILE: distilbert_finetune-0.results\n",
      "{'loss': 1.6073, 'learning_rate': 0.00045454545454545455, 'epoch': 0.23}\n",
      "{'eval_loss': 0.6572248339653015, 'eval_runtime': 3.583, 'eval_samples_per_second': 907.057, 'eval_steps_per_second': 28.468, 'epoch': 0.23}\n",
      "{'loss': 0.4214, 'learning_rate': 0.0009090909090909091, 'epoch': 0.46}\n",
      "{'eval_loss': 0.3716103434562683, 'eval_runtime': 3.6002, 'eval_samples_per_second': 902.719, 'eval_steps_per_second': 28.331, 'epoch': 0.46}\n",
      "{'loss': 0.2853, 'learning_rate': 0.0009594936708860759, 'epoch': 0.68}\n",
      "{'eval_loss': 0.2914929687976837, 'eval_runtime': 3.6688, 'eval_samples_per_second': 885.847, 'eval_steps_per_second': 27.802, 'epoch': 0.68}\n",
      "{'loss': 0.2463, 'learning_rate': 0.0009088607594936709, 'epoch': 0.91}\n",
      "{'eval_loss': 0.25808992981910706, 'eval_runtime': 3.59, 'eval_samples_per_second': 905.291, 'eval_steps_per_second': 28.412, 'epoch': 0.91}\n",
      "{'loss': 0.2247, 'learning_rate': 0.0008582278481012659, 'epoch': 1.14}\n",
      "{'eval_loss': 0.23791661858558655, 'eval_runtime': 3.6806, 'eval_samples_per_second': 883.008, 'eval_steps_per_second': 27.713, 'epoch': 1.14}\n",
      "{'loss': 0.1952, 'learning_rate': 0.0008075949367088608, 'epoch': 1.37}\n",
      "{'eval_loss': 0.22739695012569427, 'eval_runtime': 3.6562, 'eval_samples_per_second': 888.911, 'eval_steps_per_second': 27.898, 'epoch': 1.37}\n",
      "{'loss': 0.1916, 'learning_rate': 0.0007569620253164558, 'epoch': 1.59}\n",
      "{'eval_loss': 0.22110144793987274, 'eval_runtime': 3.6879, 'eval_samples_per_second': 881.257, 'eval_steps_per_second': 27.658, 'epoch': 1.59}\n",
      "{'loss': 0.1905, 'learning_rate': 0.0007063291139240506, 'epoch': 1.82}\n",
      "{'eval_loss': 0.2130526602268219, 'eval_runtime': 3.592, 'eval_samples_per_second': 904.783, 'eval_steps_per_second': 28.396, 'epoch': 1.82}\n",
      "{'loss': 0.18, 'learning_rate': 0.0006556962025316456, 'epoch': 2.05}\n",
      "{'eval_loss': 0.20900766551494598, 'eval_runtime': 3.6288, 'eval_samples_per_second': 895.614, 'eval_steps_per_second': 28.109, 'epoch': 2.05}\n",
      "{'loss': 0.1723, 'learning_rate': 0.0006050632911392405, 'epoch': 2.28}\n",
      "{'eval_loss': 0.20580355823040009, 'eval_runtime': 3.5627, 'eval_samples_per_second': 912.237, 'eval_steps_per_second': 28.63, 'epoch': 2.28}\n",
      "{'loss': 0.1763, 'learning_rate': 0.0005544303797468354, 'epoch': 2.51}\n",
      "{'eval_loss': 0.20202945172786713, 'eval_runtime': 3.5797, 'eval_samples_per_second': 907.904, 'eval_steps_per_second': 28.494, 'epoch': 2.51}\n",
      "{'loss': 0.1736, 'learning_rate': 0.0005037974683544304, 'epoch': 2.73}\n",
      "{'eval_loss': 0.1989457607269287, 'eval_runtime': 3.5703, 'eval_samples_per_second': 910.285, 'eval_steps_per_second': 28.569, 'epoch': 2.73}\n",
      "{'loss': 0.1625, 'learning_rate': 0.0004531645569620253, 'epoch': 2.96}\n",
      "{'eval_loss': 0.1965002417564392, 'eval_runtime': 3.6111, 'eval_samples_per_second': 900.002, 'eval_steps_per_second': 28.246, 'epoch': 2.96}\n",
      "{'loss': 0.1651, 'learning_rate': 0.00040253164556962025, 'epoch': 3.19}\n",
      "{'eval_loss': 0.19496193528175354, 'eval_runtime': 3.5893, 'eval_samples_per_second': 905.468, 'eval_steps_per_second': 28.418, 'epoch': 3.19}\n",
      "{'loss': 0.167, 'learning_rate': 0.0003518987341772152, 'epoch': 3.42}\n",
      "{'eval_loss': 0.1945277601480484, 'eval_runtime': 3.6056, 'eval_samples_per_second': 901.375, 'eval_steps_per_second': 28.289, 'epoch': 3.42}\n",
      "{'loss': 0.1633, 'learning_rate': 0.0003012658227848101, 'epoch': 3.64}\n",
      "{'eval_loss': 0.19345086812973022, 'eval_runtime': 3.6208, 'eval_samples_per_second': 897.581, 'eval_steps_per_second': 28.17, 'epoch': 3.64}\n",
      "{'loss': 0.1627, 'learning_rate': 0.00025063291139240505, 'epoch': 3.87}\n",
      "{'eval_loss': 0.191795215010643, 'eval_runtime': 3.6027, 'eval_samples_per_second': 902.11, 'eval_steps_per_second': 28.312, 'epoch': 3.87}\n",
      "{'loss': 0.1558, 'learning_rate': 0.0002, 'epoch': 4.1}\n",
      "{'eval_loss': 0.19030356407165527, 'eval_runtime': 3.6137, 'eval_samples_per_second': 899.359, 'eval_steps_per_second': 28.226, 'epoch': 4.1}\n",
      "{'loss': 0.1606, 'learning_rate': 0.00014936708860759494, 'epoch': 4.33}\n",
      "{'eval_loss': 0.19019031524658203, 'eval_runtime': 3.5995, 'eval_samples_per_second': 902.892, 'eval_steps_per_second': 28.337, 'epoch': 4.33}\n",
      "{'loss': 0.1644, 'learning_rate': 9.873417721518988e-05, 'epoch': 4.56}\n",
      "{'eval_loss': 0.18955326080322266, 'eval_runtime': 3.6194, 'eval_samples_per_second': 897.933, 'eval_steps_per_second': 28.181, 'epoch': 4.56}\n",
      "{'loss': 0.1502, 'learning_rate': 4.810126582278481e-05, 'epoch': 4.78}\n",
      "{'eval_loss': 0.18925593793392181, 'eval_runtime': 3.6232, 'eval_samples_per_second': 897.009, 'eval_steps_per_second': 28.152, 'epoch': 4.78}\n",
      "{'train_runtime': 221.6382, 'train_samples_per_second': 316.755, 'train_steps_per_second': 9.904, 'train_loss': 0.25841632399852293, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:06<00:00, 66.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --model distilbert --finetune_mode 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (../conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6)\n",
      "100%|██████████| 15/15 [00:01<00:00, 10.91ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.03ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.49ba/s]\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 14041\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2195\n",
      "  5%|▍         | 100/2195 [00:17<05:55,  5.89it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.84it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.24it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 34.05it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.58it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.73it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.92it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.52it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.26it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 30.13it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 30.03it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.68it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.54it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.99it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 36.06it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.81it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.32it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.71it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.72it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.00it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.63it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.73it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.59it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.68it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.14it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.85it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.53it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.38it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.35it/s]\u001b[A\n",
      "                                                  A\n",
      "  5%|▍         | 100/2195 [00:20<05:55,  5.89it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.72it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000] due to args.save_total_limit\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100] due to args.save_total_limit\n",
      "  9%|▉         | 200/2195 [00:38<05:21,  6.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.68it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.89it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.82it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.55it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.60it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.99it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.63it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.30it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.81it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.76it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.52it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.29it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.67it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.73it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.19it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 36.75it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.13it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.25it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.59it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.21it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.31it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.14it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.45it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 20.97it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.68it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.47it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.32it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.29it/s]\u001b[A\n",
      "                                                  A\n",
      "  9%|▉         | 200/2195 [00:42<05:21,  6.21it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.73it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_0] due to args.save_total_limit\n",
      " 14%|█▎        | 300/2195 [00:59<04:56,  6.39it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.59it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 34.92it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.15it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.06it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 31.18it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 30.53it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:00<00:02, 30.19it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 29.98it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 29.84it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 29.81it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 31.98it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 33.75it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 35.12it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 36.09it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 36.82it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.35it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 37.67it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 33.65it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 28.08it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.19it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.50it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.37it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.66it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.17it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.85it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.60it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.43it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:03<00:00, 22.93it/s]\u001b[A\n",
      "                                                  [A\n",
      " 14%|█▎        | 300/2195 [01:03<04:56,  6.39it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 26.24it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-100] due to args.save_total_limit\n",
      " 18%|█▊        | 400/2195 [01:22<04:58,  6.01it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.72it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 34.81it/s]\u001b[A\n",
      " 12%|█▏        | 12/102 [00:00<00:02, 33.32it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 32.19it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 31.42it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.96it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.63it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 30.41it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 30.21it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.82it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.80it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 35.24it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 36.38it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 37.33it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 38.00it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 38.32it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 36.22it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.29it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.86it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.87it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.67it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.84it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.31it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:02<00:00, 21.04it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.78it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.62it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.64it/s]\u001b[A\n",
      "                                                  [A\n",
      " 18%|█▊        | 400/2195 [01:27<04:58,  6.01it/s]\n",
      "100%|██████████| 102/102 [00:05<00:00, 25.18it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-200] due to args.save_total_limit\n",
      " 23%|██▎       | 500/2195 [01:46<04:45,  5.93it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.52it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.94it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.86it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.58it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.84it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 31.35it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.97it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.60it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:02, 30.96it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 32.99it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 34.34it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:01<00:01, 35.15it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:01<00:01, 36.23it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:01<00:01, 36.92it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:01<00:01, 37.41it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:01<00:01, 37.67it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:01<00:01, 31.58it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:02<00:01, 26.83it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 24.46it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.08it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.18it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.62it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.26it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.93it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.67it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.35it/s]\u001b[A\n",
      " 94%|█████████▍| 96/102 [00:03<00:00, 22.50it/s]\u001b[A\n",
      "                                                  [A\n",
      " 23%|██▎       | 500/2195 [01:50<04:45,  5.93it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.81it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-300] due to args.save_total_limit\n",
      " 27%|██▋       | 600/2195 [02:08<04:25,  6.01it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.74it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.18it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.96it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.55it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.56it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.99it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.51it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.20it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.98it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.77it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.29it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.05it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.57it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.77it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.59it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.14it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.61it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.68it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.13it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.78it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.53it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.38it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.76it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.33it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.90it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.62it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.43it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.37it/s]\u001b[A\n",
      "                                                  A\n",
      " 27%|██▋       | 600/2195 [02:12<04:25,  6.01it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.76it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-400] due to args.save_total_limit\n",
      " 32%|███▏      | 700/2195 [02:35<04:08,  6.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.96it/s]\u001b[A\n",
      "  9%|▉         | 9/102 [00:00<00:02, 35.30it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 33.72it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 32.69it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 32.05it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 31.43it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 31.06it/s]\u001b[A\n",
      " 32%|███▏      | 33/102 [00:01<00:02, 31.31it/s]\u001b[A\n",
      " 36%|███▋      | 37/102 [00:01<00:01, 33.25it/s]\u001b[A\n",
      " 40%|████      | 41/102 [00:01<00:01, 34.86it/s]\u001b[A\n",
      " 44%|████▍     | 45/102 [00:01<00:01, 35.99it/s]\u001b[A\n",
      " 48%|████▊     | 49/102 [00:01<00:01, 37.01it/s]\u001b[A\n",
      " 52%|█████▏    | 53/102 [00:01<00:01, 37.72it/s]\u001b[A\n",
      " 56%|█████▌    | 57/102 [00:01<00:01, 38.25it/s]\u001b[A\n",
      " 60%|█████▉    | 61/102 [00:01<00:01, 38.65it/s]\u001b[A\n",
      " 64%|██████▎   | 65/102 [00:01<00:01, 32.28it/s]\u001b[A\n",
      " 68%|██████▊   | 69/102 [00:02<00:01, 27.54it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 24.86it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.33it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.34it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.66it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.26it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.98it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.69it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.36it/s]\u001b[A\n",
      " 95%|█████████▌| 97/102 [00:03<00:00, 22.93it/s]\u001b[A\n",
      "                                                  [A\n",
      " 32%|███▏      | 700/2195 [02:39<04:08,  6.02it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 26.73it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-500] due to args.save_total_limit\n",
      " 36%|███▋      | 800/2195 [02:56<03:49,  6.07it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.66it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.02it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.98it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.61it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.70it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 31.01it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.63it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.37it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 30.08it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.90it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.50it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.35it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.65it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.86it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.83it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.23it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.62it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.72it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.90it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 24.96it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.34it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.26it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.56it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.07it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.71it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.46it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.31it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.29it/s]\u001b[A\n",
      "                                                  A\n",
      " 36%|███▋      | 800/2195 [03:00<03:49,  6.07it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.71it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-600] due to args.save_total_limit\n",
      " 41%|████      | 900/2195 [03:18<03:22,  6.39it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 37.95it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.10it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.18it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 31.63it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 30.17it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 29.98it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 29.80it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 29.70it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.59it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.64it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.27it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.17it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.74it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.99it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.81it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.31it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.84it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.83it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.01it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.57it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.62it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.45it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.66it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.10it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.74it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.57it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.42it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.42it/s]\u001b[A\n",
      "                                                  A\n",
      " 41%|████      | 900/2195 [03:21<03:22,  6.39it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.86it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-700] due to args.save_total_limit\n",
      " 46%|████▌     | 1000/2195 [03:39<03:14,  6.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 38.09it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.03it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.15it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 31.91it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.17it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.64it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.32it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.11it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.98it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.91it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.46it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.44it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.92it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 36.07it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.98it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.62it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.98it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.79it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.05it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.56it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.58it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.43it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.58it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 20.99it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.69it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.41it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.28it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.25it/s]\u001b[A\n",
      "                                                   \n",
      " 46%|████▌     | 1000/2195 [03:43<03:14,  6.15it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.60it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-800] due to args.save_total_limit\n",
      " 50%|█████     | 1100/2195 [04:01<03:03,  5.97it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.60it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.87it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.69it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.35it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.48it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.91it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.51it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.22it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 30.02it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.35it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.02it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 32.95it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.46it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.61it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.52it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.02it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.45it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.47it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.90it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.52it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.61it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.38it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.58it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.06it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.72it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.47it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.29it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.26it/s]\u001b[A\n",
      "                                                   \n",
      " 50%|█████     | 1100/2195 [04:04<03:03,  5.97it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.58it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-900] due to args.save_total_limit\n",
      " 55%|█████▍    | 1200/2195 [04:22<02:42,  6.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.58it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.05it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.86it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.43it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.45it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.77it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.40it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.17it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.90it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.62it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.27it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.22it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.61it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.71it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.53it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.08it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.47it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.52it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.88it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.51it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.45it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.23it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.44it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.00it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.60it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.40it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.29it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.24it/s]\u001b[A\n",
      "                                                   \n",
      " 55%|█████▍    | 1200/2195 [04:26<02:42,  6.13it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.65it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1000] due to args.save_total_limit\n",
      " 59%|█████▉    | 1300/2195 [04:44<02:30,  5.95it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.51it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.88it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.83it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.53it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.66it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.99it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.49it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.15it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.91it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.59it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.24it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.18it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.68it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.81it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.76it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.29it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.75it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.75it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.12it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.68it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.65it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.41it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.63it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.11it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.75it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.47it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.31it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.26it/s]\u001b[A\n",
      "                                                   \n",
      " 59%|█████▉    | 1300/2195 [04:47<02:30,  5.95it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.66it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1100] due to args.save_total_limit\n",
      " 64%|██████▍   | 1400/2195 [05:05<02:13,  5.98it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.31it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.65it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.54it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.21it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.39it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.87it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.50it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.23it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.99it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.49it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.14it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.13it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.64it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.66it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.48it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.01it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.59it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.66it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.04it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.64it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.71it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.46it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.68it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.12it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.77it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.49it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.33it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.29it/s]\u001b[A\n",
      "                                                   \n",
      " 64%|██████▍   | 1400/2195 [05:08<02:13,  5.98it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.71it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1200] due to args.save_total_limit\n",
      " 68%|██████▊   | 1500/2195 [05:26<01:53,  6.14it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.74it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 34.85it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.09it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.03it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 31.30it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 30.82it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 30.56it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.29it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 30.03it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 30.97it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.04it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.48it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 35.56it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 36.39it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:01<00:01, 36.95it/s]\u001b[A\n",
      " 57%|█████▋    | 58/102 [00:01<00:01, 37.45it/s]\u001b[A\n",
      " 61%|██████    | 62/102 [00:01<00:01, 37.89it/s]\u001b[A\n",
      " 65%|██████▍   | 66/102 [00:02<00:01, 30.18it/s]\u001b[A\n",
      " 69%|██████▊   | 70/102 [00:02<00:01, 26.28it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 24.01it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 22.57it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 21.68it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.14it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 20.75it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.53it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.33it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.28it/s]\u001b[A\n",
      "                                                   \n",
      " 68%|██████▊   | 1500/2195 [05:30<01:53,  6.14it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 23.75it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1300] due to args.save_total_limit\n",
      " 73%|███████▎  | 1600/2195 [05:47<01:30,  6.60it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.63it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.01it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.83it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.48it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.64it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 31.04it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.58it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.24it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.95it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.75it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.30it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.08it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.32it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.44it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.21it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 36.85it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.41it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.52it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.87it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.49it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.52it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.22it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.44it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 20.97it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.61it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.32it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.14it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.10it/s]\u001b[A\n",
      "                                                   \n",
      " 73%|███████▎  | 1600/2195 [05:51<01:30,  6.60it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.38it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1400] due to args.save_total_limit\n",
      " 77%|███████▋  | 1700/2195 [06:08<01:15,  6.55it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 5/102 [00:00<00:02, 37.50it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 34.70it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.11it/s]\u001b[A\n",
      " 15%|█▍        | 15/102 [00:00<00:02, 32.11it/s]\u001b[A\n",
      " 18%|█▊        | 18/102 [00:00<00:02, 31.35it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 30.85it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 30.39it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.11it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 29.92it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 30.97it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.15it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.69it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 35.96it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 36.93it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:01<00:01, 37.50it/s]\u001b[A\n",
      " 57%|█████▋    | 58/102 [00:01<00:01, 37.85it/s]\u001b[A\n",
      " 61%|██████    | 62/102 [00:01<00:01, 37.79it/s]\u001b[A\n",
      " 65%|██████▍   | 66/102 [00:02<00:01, 30.01it/s]\u001b[A\n",
      " 69%|██████▊   | 70/102 [00:02<00:01, 26.08it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 23.89it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 22.56it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 21.71it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.13it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 20.77it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.53it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.37it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.22it/s]\u001b[A\n",
      "                                                   \n",
      " 77%|███████▋  | 1700/2195 [06:12<01:15,  6.55it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 23.65it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1500] due to args.save_total_limit\n",
      " 82%|████████▏ | 1800/2195 [06:30<01:00,  6.49it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.58it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.85it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.69it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.33it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.51it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.90it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.44it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 29.98it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.73it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.69it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.36it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 33.26it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.76it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.98it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.73it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.34it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.76it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.76it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 29.01it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.57it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.70it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.55it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.82it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 21.21it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.87it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.63it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.43it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.39it/s]\u001b[A\n",
      "                                                   \n",
      " 82%|████████▏ | 1800/2195 [06:34<01:00,  6.49it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.82it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1600] due to args.save_total_limit\n",
      " 87%|████████▋ | 1900/2195 [06:51<00:49,  5.95it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.83it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 36.07it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.97it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.74it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 31.86it/s]\u001b[A\n",
      " 21%|██        | 21/102 [00:00<00:02, 31.27it/s]\u001b[A\n",
      " 24%|██▎       | 24/102 [00:00<00:02, 30.63it/s]\u001b[A\n",
      " 26%|██▋       | 27/102 [00:00<00:02, 30.39it/s]\u001b[A\n",
      " 29%|██▉       | 30/102 [00:00<00:02, 30.12it/s]\u001b[A\n",
      " 33%|███▎      | 34/102 [00:01<00:02, 31.14it/s]\u001b[A\n",
      " 37%|███▋      | 38/102 [00:01<00:01, 33.07it/s]\u001b[A\n",
      " 41%|████      | 42/102 [00:01<00:01, 34.55it/s]\u001b[A\n",
      " 45%|████▌     | 46/102 [00:01<00:01, 35.33it/s]\u001b[A\n",
      " 49%|████▉     | 50/102 [00:01<00:01, 36.42it/s]\u001b[A\n",
      " 53%|█████▎    | 54/102 [00:01<00:01, 37.05it/s]\u001b[A\n",
      " 57%|█████▋    | 58/102 [00:01<00:01, 37.57it/s]\u001b[A\n",
      " 61%|██████    | 62/102 [00:01<00:01, 37.83it/s]\u001b[A\n",
      " 65%|██████▍   | 66/102 [00:02<00:01, 29.90it/s]\u001b[A\n",
      " 69%|██████▊   | 70/102 [00:02<00:01, 25.87it/s]\u001b[A\n",
      " 72%|███████▏  | 73/102 [00:02<00:01, 23.83it/s]\u001b[A\n",
      " 75%|███████▍  | 76/102 [00:02<00:01, 22.55it/s]\u001b[A\n",
      " 77%|███████▋  | 79/102 [00:02<00:01, 21.70it/s]\u001b[A\n",
      " 80%|████████  | 82/102 [00:02<00:00, 21.24it/s]\u001b[A\n",
      " 83%|████████▎ | 85/102 [00:02<00:00, 20.92it/s]\u001b[A\n",
      " 86%|████████▋ | 88/102 [00:03<00:00, 20.68it/s]\u001b[A\n",
      " 89%|████████▉ | 91/102 [00:03<00:00, 20.45it/s]\u001b[A\n",
      " 92%|█████████▏| 94/102 [00:03<00:00, 20.32it/s]\u001b[A\n",
      "                                                   \n",
      " 87%|████████▋ | 1900/2195 [06:55<00:49,  5.95it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 23.79it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1700] due to args.save_total_limit\n",
      " 91%|█████████ | 2000/2195 [07:12<00:32,  6.01it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.52it/s]\u001b[A\n",
      "  7%|▋         | 7/102 [00:00<00:02, 35.74it/s]\u001b[A\n",
      " 10%|▉         | 10/102 [00:00<00:02, 33.60it/s]\u001b[A\n",
      " 13%|█▎        | 13/102 [00:00<00:02, 32.27it/s]\u001b[A\n",
      " 16%|█▌        | 16/102 [00:00<00:02, 31.35it/s]\u001b[A\n",
      " 19%|█▊        | 19/102 [00:00<00:02, 30.68it/s]\u001b[A\n",
      " 22%|██▏       | 22/102 [00:00<00:02, 30.27it/s]\u001b[A\n",
      " 25%|██▍       | 25/102 [00:00<00:02, 30.03it/s]\u001b[A\n",
      " 27%|██▋       | 28/102 [00:00<00:02, 29.79it/s]\u001b[A\n",
      " 30%|███       | 31/102 [00:01<00:02, 29.56it/s]\u001b[A\n",
      " 34%|███▍      | 35/102 [00:01<00:02, 31.09it/s]\u001b[A\n",
      " 38%|███▊      | 39/102 [00:01<00:01, 32.88it/s]\u001b[A\n",
      " 42%|████▏     | 43/102 [00:01<00:01, 34.20it/s]\u001b[A\n",
      " 46%|████▌     | 47/102 [00:01<00:01, 35.35it/s]\u001b[A\n",
      " 50%|█████     | 51/102 [00:01<00:01, 36.32it/s]\u001b[A\n",
      " 54%|█████▍    | 55/102 [00:01<00:01, 37.06it/s]\u001b[A\n",
      " 58%|█████▊    | 59/102 [00:01<00:01, 37.48it/s]\u001b[A\n",
      " 62%|██████▏   | 63/102 [00:01<00:01, 35.35it/s]\u001b[A\n",
      " 66%|██████▌   | 67/102 [00:02<00:01, 28.58it/s]\u001b[A\n",
      " 70%|██████▉   | 71/102 [00:02<00:01, 25.32it/s]\u001b[A\n",
      " 73%|███████▎  | 74/102 [00:02<00:01, 23.45it/s]\u001b[A\n",
      " 75%|███████▌  | 77/102 [00:02<00:01, 22.26it/s]\u001b[A\n",
      " 78%|███████▊  | 80/102 [00:02<00:01, 21.49it/s]\u001b[A\n",
      " 81%|████████▏ | 83/102 [00:02<00:00, 20.99it/s]\u001b[A\n",
      " 84%|████████▍ | 86/102 [00:03<00:00, 20.67it/s]\u001b[A\n",
      " 87%|████████▋ | 89/102 [00:03<00:00, 20.46it/s]\u001b[A\n",
      " 90%|█████████ | 92/102 [00:03<00:00, 20.34it/s]\u001b[A\n",
      " 93%|█████████▎| 95/102 [00:03<00:00, 21.32it/s]\u001b[A\n",
      "                                                   \n",
      " 91%|█████████ | 2000/2195 [07:16<00:32,  6.01it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 24.70it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1800] due to args.save_total_limit\n",
      " 96%|█████████▌| 2100/2195 [07:33<00:15,  6.27it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3250\n",
      "  Batch size = 32\n",
      "\n",
      "  0%|          | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 4/102 [00:00<00:02, 39.74it/s]\u001b[A\n",
      "  8%|▊         | 8/102 [00:00<00:02, 36.21it/s]\u001b[A\n",
      " 11%|█         | 11/102 [00:00<00:02, 33.98it/s]\u001b[A\n",
      " 14%|█▎        | 14/102 [00:00<00:02, 32.45it/s]\u001b[A\n",
      " 17%|█▋        | 17/102 [00:00<00:02, 31.55it/s]\u001b[A\n",
      " 20%|█▉        | 20/102 [00:00<00:02, 30.93it/s]\u001b[A\n",
      " 23%|██▎       | 23/102 [00:00<00:02, 30.27it/s]\u001b[A\n",
      " 25%|██▌       | 26/102 [00:00<00:02, 30.16it/s]\u001b[A\n",
      " 28%|██▊       | 29/102 [00:00<00:02, 30.01it/s]\u001b[A\n",
      " 31%|███▏      | 32/102 [00:01<00:02, 29.96it/s]\u001b[A\n",
      " 35%|███▌      | 36/102 [00:01<00:02, 32.11it/s]\u001b[A\n",
      " 39%|███▉      | 40/102 [00:01<00:01, 33.91it/s]\u001b[A\n",
      " 43%|████▎     | 44/102 [00:01<00:01, 35.10it/s]\u001b[A\n",
      " 47%|████▋     | 48/102 [00:01<00:01, 36.16it/s]\u001b[A\n",
      " 51%|█████     | 52/102 [00:01<00:01, 37.03it/s]\u001b[A\n",
      " 55%|█████▍    | 56/102 [00:01<00:01, 37.53it/s]\u001b[A\n",
      " 59%|█████▉    | 60/102 [00:01<00:01, 37.86it/s]\u001b[A\n",
      " 63%|██████▎   | 64/102 [00:01<00:01, 33.69it/s]\u001b[A\n",
      " 67%|██████▋   | 68/102 [00:02<00:01, 28.06it/s]\u001b[A\n",
      " 71%|███████   | 72/102 [00:02<00:01, 25.17it/s]\u001b[A\n",
      " 74%|███████▎  | 75/102 [00:02<00:01, 23.31it/s]\u001b[A\n",
      " 76%|███████▋  | 78/102 [00:02<00:01, 22.26it/s]\u001b[A\n",
      " 79%|███████▉  | 81/102 [00:02<00:00, 21.48it/s]\u001b[A\n",
      " 82%|████████▏ | 84/102 [00:02<00:00, 21.01it/s]\u001b[A\n",
      " 85%|████████▌ | 87/102 [00:03<00:00, 20.67it/s]\u001b[A\n",
      " 88%|████████▊ | 90/102 [00:03<00:00, 20.46it/s]\u001b[A\n",
      " 91%|█████████ | 93/102 [00:03<00:00, 20.29it/s]\u001b[A\n",
      " 94%|█████████▍| 96/102 [00:03<00:00, 22.38it/s]\u001b[A\n",
      "                                                   A\n",
      " 96%|█████████▌| 2100/2195 [07:37<00:15,  6.27it/s]\n",
      "100%|██████████| 102/102 [00:03<00:00, 25.68it/s]\u001b[A\n",
      "                                                 \u001b[ASaving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100/special_tokens_map.json\n",
      "Deleting older checkpoint [/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-1900] due to args.save_total_limit\n",
      "100%|██████████| 2195/2195 [07:54<00:00,  6.67it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-2100 (score: 0.05914109945297241).\n",
      "100%|██████████| 2195/2195 [07:54<00:00,  4.63it/s]\n",
      "Saving model checkpoint to /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_1\n",
      "Configuration saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_1/config.json\n",
      "Model weights saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_1/pytorch_model.bin\n",
      "tokenizer config file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_1/tokenizer_config.json\n",
      "Special tokens file saved in /raid/home/jeremiec/Data/NER/BERT_and_DistilBERT/checkpoint-best-distilbert_finetune_1/special_tokens_map.json\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, id, pos_tags, chunk_tags, tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3453\n",
      "  Batch size = 8\n",
      " 99%|█████████▉| 429/432 [00:05<00:00, 81.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS_FILE: distilbert_finetune-1.results\n",
      "{'loss': 1.4669, 'learning_rate': 4.5454545454545455e-06, 'epoch': 0.23}\n",
      "{'eval_loss': 1.2744009494781494, 'eval_runtime': 3.6378, 'eval_samples_per_second': 893.401, 'eval_steps_per_second': 28.039, 'epoch': 0.23}\n",
      "{'loss': 0.3594, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.46}\n",
      "{'eval_loss': 0.39810264110565186, 'eval_runtime': 3.6671, 'eval_samples_per_second': 886.253, 'eval_steps_per_second': 27.815, 'epoch': 0.46}\n",
      "{'loss': 0.1646, 'learning_rate': 9.59493670886076e-06, 'epoch': 0.68}\n",
      "{'eval_loss': 0.2012368142604828, 'eval_runtime': 3.6352, 'eval_samples_per_second': 894.025, 'eval_steps_per_second': 28.059, 'epoch': 0.68}\n",
      "{'loss': 0.1218, 'learning_rate': 9.08860759493671e-06, 'epoch': 0.91}\n",
      "{'eval_loss': 0.13945278525352478, 'eval_runtime': 3.6008, 'eval_samples_per_second': 902.581, 'eval_steps_per_second': 28.327, 'epoch': 0.91}\n",
      "{'loss': 0.0991, 'learning_rate': 8.582278481012659e-06, 'epoch': 1.14}\n",
      "{'eval_loss': 0.11785471439361572, 'eval_runtime': 3.6323, 'eval_samples_per_second': 894.754, 'eval_steps_per_second': 28.082, 'epoch': 1.14}\n",
      "{'loss': 0.0788, 'learning_rate': 8.075949367088608e-06, 'epoch': 1.37}\n",
      "{'eval_loss': 0.10376307368278503, 'eval_runtime': 3.6407, 'eval_samples_per_second': 892.675, 'eval_steps_per_second': 28.016, 'epoch': 1.37}\n",
      "{'loss': 0.0728, 'learning_rate': 7.569620253164558e-06, 'epoch': 1.59}\n",
      "{'eval_loss': 0.09287501871585846, 'eval_runtime': 3.5856, 'eval_samples_per_second': 906.393, 'eval_steps_per_second': 28.447, 'epoch': 1.59}\n",
      "{'loss': 0.0732, 'learning_rate': 7.0632911392405065e-06, 'epoch': 1.82}\n",
      "{'eval_loss': 0.08390922844409943, 'eval_runtime': 3.6557, 'eval_samples_per_second': 889.016, 'eval_steps_per_second': 27.901, 'epoch': 1.82}\n",
      "{'loss': 0.0601, 'learning_rate': 6.5569620253164564e-06, 'epoch': 2.05}\n",
      "{'eval_loss': 0.07867461442947388, 'eval_runtime': 3.6573, 'eval_samples_per_second': 888.633, 'eval_steps_per_second': 27.889, 'epoch': 2.05}\n",
      "{'loss': 0.0517, 'learning_rate': 6.050632911392406e-06, 'epoch': 2.28}\n",
      "{'eval_loss': 0.07807326316833496, 'eval_runtime': 3.6538, 'eval_samples_per_second': 889.492, 'eval_steps_per_second': 27.916, 'epoch': 2.28}\n",
      "{'loss': 0.0503, 'learning_rate': 5.544303797468355e-06, 'epoch': 2.51}\n",
      "{'eval_loss': 0.07513836771249771, 'eval_runtime': 3.6625, 'eval_samples_per_second': 887.375, 'eval_steps_per_second': 27.85, 'epoch': 2.51}\n",
      "{'loss': 0.0513, 'learning_rate': 5.037974683544305e-06, 'epoch': 2.73}\n",
      "{'eval_loss': 0.07056237012147903, 'eval_runtime': 3.6634, 'eval_samples_per_second': 887.146, 'eval_steps_per_second': 27.843, 'epoch': 2.73}\n",
      "{'loss': 0.0421, 'learning_rate': 4.531645569620253e-06, 'epoch': 2.96}\n",
      "{'eval_loss': 0.06694649904966354, 'eval_runtime': 3.6489, 'eval_samples_per_second': 890.691, 'eval_steps_per_second': 27.954, 'epoch': 2.96}\n",
      "{'loss': 0.0403, 'learning_rate': 4.025316455696203e-06, 'epoch': 3.19}\n",
      "{'eval_loss': 0.06603844463825226, 'eval_runtime': 3.6541, 'eval_samples_per_second': 889.401, 'eval_steps_per_second': 27.913, 'epoch': 3.19}\n",
      "{'loss': 0.0382, 'learning_rate': 3.518987341772152e-06, 'epoch': 3.42}\n",
      "{'eval_loss': 0.0634988471865654, 'eval_runtime': 3.6437, 'eval_samples_per_second': 891.955, 'eval_steps_per_second': 27.994, 'epoch': 3.42}\n",
      "{'loss': 0.0376, 'learning_rate': 3.0126582278481016e-06, 'epoch': 3.64}\n",
      "{'eval_loss': 0.06523587554693222, 'eval_runtime': 3.674, 'eval_samples_per_second': 884.601, 'eval_steps_per_second': 27.763, 'epoch': 3.64}\n",
      "{'loss': 0.0364, 'learning_rate': 2.5063291139240508e-06, 'epoch': 3.87}\n",
      "{'eval_loss': 0.062341928482055664, 'eval_runtime': 3.6444, 'eval_samples_per_second': 891.773, 'eval_steps_per_second': 27.988, 'epoch': 3.87}\n",
      "{'loss': 0.0323, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.1}\n",
      "{'eval_loss': 0.06054743751883507, 'eval_runtime': 3.6416, 'eval_samples_per_second': 892.461, 'eval_steps_per_second': 28.01, 'epoch': 4.1}\n",
      "{'loss': 0.0311, 'learning_rate': 1.4936708860759495e-06, 'epoch': 4.33}\n",
      "{'eval_loss': 0.06032219156622887, 'eval_runtime': 3.6429, 'eval_samples_per_second': 892.141, 'eval_steps_per_second': 28.0, 'epoch': 4.33}\n",
      "{'loss': 0.0323, 'learning_rate': 9.873417721518988e-07, 'epoch': 4.56}\n",
      "{'eval_loss': 0.0599343366920948, 'eval_runtime': 3.6762, 'eval_samples_per_second': 884.056, 'eval_steps_per_second': 27.746, 'epoch': 4.56}\n",
      "{'loss': 0.0302, 'learning_rate': 4.810126582278482e-07, 'epoch': 4.78}\n",
      "{'eval_loss': 0.05914109945297241, 'eval_runtime': 3.6461, 'eval_samples_per_second': 891.367, 'eval_steps_per_second': 27.975, 'epoch': 4.78}\n",
      "{'train_runtime': 474.5904, 'train_samples_per_second': 147.928, 'train_steps_per_second': 4.625, 'train_loss': 0.13674014521622713, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:06<00:00, 63.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for params in tqdm(permutations_dicts):\n",
    "    \n",
    "    params_str = ''\n",
    "    \n",
    "    for k, v in params.items():\n",
    "        params_str += f\" --{k} {v}\"\n",
    "    \n",
    "    # params_str += \" --nb_epoch 5.0\"\n",
    "    \n",
    "    print(params_str)\n",
    "        \n",
    "    os.system(\"python3 bert_and_distilbert.py\" + params_str)\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb68e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cd61845",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546927f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = '/raid/home/jeremiec/Data/NER/BERT_and_DistilBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a939a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d = {}\n",
    "\n",
    "for model in ['bert', 'distilbert']:\n",
    "    \n",
    "    for ft in [0, 1]:\n",
    "        \n",
    "        filename = os.path.join(RESULTS_FOLDER, f'{model}_finetune-{ft}.results')\n",
    "        \n",
    "        with open(filename, 'rb') as fh:\n",
    "            results = pickle.load(fh)\n",
    "            results_d[f'{model}_finetune-{ft}'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59cd6003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert_finetune-0': ({'LOC': {'precision': 0.7301075268817204,\n",
       "    'recall': 0.8141486810551559,\n",
       "    'f1': 0.7698412698412698,\n",
       "    'number': 1668},\n",
       "   'MISC': {'precision': 0.7470489038785835,\n",
       "    'recall': 0.6310541310541311,\n",
       "    'f1': 0.6841698841698842,\n",
       "    'number': 702},\n",
       "   'ORG': {'precision': 0.6284848484848485,\n",
       "    'recall': 0.6243226971703792,\n",
       "    'f1': 0.6263968589549984,\n",
       "    'number': 1661},\n",
       "   'PER': {'precision': 0.9246263807667316,\n",
       "    'recall': 0.8800247371675943,\n",
       "    'f1': 0.9017743979721166,\n",
       "    'number': 1617},\n",
       "   'overall_precision': 0.7552286423254165,\n",
       "   'overall_recall': 0.7544263456090652,\n",
       "   'overall_f1': 0.7548272807794509,\n",
       "   'overall_accuracy': 0.9567136857973512},\n",
       "  417.2637),\n",
       " 'bert_finetune-1': ({'LOC': {'precision': 0.9153846153846154,\n",
       "    'recall': 0.9274580335731415,\n",
       "    'f1': 0.9213817748659916,\n",
       "    'number': 1668},\n",
       "   'MISC': {'precision': 0.7533512064343163,\n",
       "    'recall': 0.8005698005698005,\n",
       "    'f1': 0.776243093922652,\n",
       "    'number': 702},\n",
       "   'ORG': {'precision': 0.8568142610695803,\n",
       "    'recall': 0.8970499698976521,\n",
       "    'f1': 0.8764705882352941,\n",
       "    'number': 1661},\n",
       "   'PER': {'precision': 0.9671302149178256,\n",
       "    'recall': 0.9461966604823747,\n",
       "    'f1': 0.9565489215379807,\n",
       "    'number': 1617},\n",
       "   'overall_precision': 0.8909154073302067,\n",
       "   'overall_recall': 0.9081090651558074,\n",
       "   'overall_f1': 0.8994300745287155,\n",
       "   'overall_accuracy': 0.9806826747065791},\n",
       "  897.3134),\n",
       " 'distilbert_finetune-0': ({'LOC': {'precision': 0.6749192680301399,\n",
       "    'recall': 0.7517985611510791,\n",
       "    'f1': 0.711287577992059,\n",
       "    'number': 1668},\n",
       "   'MISC': {'precision': 0.6885245901639344,\n",
       "    'recall': 0.5384615384615384,\n",
       "    'f1': 0.6043165467625898,\n",
       "    'number': 702},\n",
       "   'ORG': {'precision': 0.5134362492853058,\n",
       "    'recall': 0.5406381697772427,\n",
       "    'f1': 0.5266862170087976,\n",
       "    'number': 1661},\n",
       "   'PER': {'precision': 0.770663562281723,\n",
       "    'recall': 0.8188002473716759,\n",
       "    'f1': 0.7940029985007496,\n",
       "    'number': 1617},\n",
       "   'overall_precision': 0.6561116785835887,\n",
       "   'overall_recall': 0.6823654390934845,\n",
       "   'overall_f1': 0.6689810796736677,\n",
       "   'overall_accuracy': 0.9417249919241951},\n",
       "  221.6382),\n",
       " 'distilbert_finetune-1': ({'LOC': {'precision': 0.8812758417011223,\n",
       "    'recall': 0.894484412470024,\n",
       "    'f1': 0.8878310026777744,\n",
       "    'number': 1668},\n",
       "   'MISC': {'precision': 0.6903225806451613,\n",
       "    'recall': 0.7621082621082621,\n",
       "    'f1': 0.7244414353419093,\n",
       "    'number': 702},\n",
       "   'ORG': {'precision': 0.8064889918887601,\n",
       "    'recall': 0.8380493678506924,\n",
       "    'f1': 0.8219663418954828,\n",
       "    'number': 1661},\n",
       "   'PER': {'precision': 0.9504702194357367,\n",
       "    'recall': 0.9375386518243661,\n",
       "    'f1': 0.9439601494396015,\n",
       "    'number': 1617},\n",
       "   'overall_precision': 0.8524788391777509,\n",
       "   'overall_recall': 0.8737606232294618,\n",
       "   'overall_f1': 0.862988545947364,\n",
       "   'overall_accuracy': 0.9747819532680091},\n",
       "  474.5904)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4287c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
